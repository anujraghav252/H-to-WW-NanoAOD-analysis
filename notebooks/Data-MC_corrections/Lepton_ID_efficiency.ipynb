{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5a1c77-bae8-4088-808c-1906a0bdd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc \n",
    "import psutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "print(\"All imports added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d10aa7-c651-4c66-8946-fd5b1f3644ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-fa248556-f618-11f0-8efb-86e564a09735</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/anujraghav.physics@gmail.com/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-04174710-84bb-4492-8db4-66f7033134e2</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://192.168.161.139:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.161.139:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c589be-5981-4398-8624-b4ce9f8e4eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR:         /home/cms-jovyan\n",
      "PROJECT_DIR:     /home/cms-jovyan/H-to-WW-NanoAOD-analysis\n",
      "DATA_DIR:        /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/DATA\n",
      "MC_DIR:          /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/MC_samples\n",
      "AUX_DIR:         /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files\n",
      "GOLDEN_JSON:      /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\n",
      "JSON exists:     True\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = Path(os.environ.get(\"HOME\", \"/home/cms-jovyan\"))\n",
    "PROJECT_NAME = \"H-to-WW-NanoAOD-analysis\"\n",
    "\n",
    "PROJECT_DIR = HOME_DIR / PROJECT_NAME\n",
    "DATASETS_DIR = PROJECT_DIR / \"Datasets\"\n",
    "DATA_DIR = DATASETS_DIR / \"DATA\"\n",
    "MC_DIR = DATASETS_DIR / \"MC_samples\"\n",
    "AUX_DIR = PROJECT_DIR / \"Auxillary_files\"\n",
    "\n",
    "GOLDEN_JSON_PATH = AUX_DIR / \"Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\"\n",
    "\n",
    "RUN_PERIODS_2016 = {\n",
    "    \"Run2016G\": {\"run_min\": 278820, \"run_max\": 280385},\n",
    "    \"Run2016H\": {\"run_min\": 280919, \"run_max\": 284044}\n",
    "}\n",
    "\n",
    "print(f\"HOME_DIR:         {HOME_DIR}\")\n",
    "print(f\"PROJECT_DIR:     {PROJECT_DIR}\")\n",
    "print(f\"DATA_DIR:        {DATA_DIR}\")\n",
    "print(f\"MC_DIR:          {MC_DIR}\")\n",
    "print(f\"AUX_DIR:         {AUX_DIR}\")\n",
    "print(f\"GOLDEN_JSON:      {GOLDEN_JSON_PATH}\")\n",
    "print(f\"JSON exists:     {GOLDEN_JSON_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f6fecbc-f3c4-41a6-9201-51598abd668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unknown file: VG.txt- skipping\n",
      " unknown file: Higgs.txt- skipping\n",
      " unknown file: WW.txt- skipping\n",
      " unknown file: Fakes.txt- skipping\n",
      " unknown file: VZ.txt- skipping\n",
      " unknown file: ggWW.txt- skipping\n",
      " unknown file: Top.txt- skipping\n",
      "\n",
      "======================================================================\n",
      "FILES TO PROCESS\n",
      "======================================================================\n",
      "Data                :   48 files\n",
      "DY_to_Tau_Tau       :   61 files\n",
      "______________________________________________________________________\n",
      "TOTAL               :  109 files\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_MAPPING = {\n",
    "    'data' : \"Data\",\n",
    "    'dytoll' : \"DY_to_Tau_Tau\",\n",
    "}\n",
    "\n",
    "def load_urls_from_files(filepath, max_files = None):\n",
    "    urls = []\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        return urls\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('root://'):\n",
    "                urls.append(line)\n",
    "                if max_files and len(urls) >= max_files:\n",
    "                    break\n",
    "    return urls\n",
    "\n",
    "def load_all_files(data_dir, mc_dir, max_per_sample = None):\n",
    "\n",
    "    files_dict = {}\n",
    "\n",
    "    for directory in [data_dir, mc_dir]:\n",
    "        if not os.path.exists(directory):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            filename_lower = filename.lower().replace('.txt', '')\n",
    "\n",
    "            label = None\n",
    "\n",
    "            for pattern, sample_label in SAMPLE_MAPPING.items():\n",
    "                if pattern in filename_lower:\n",
    "                    label = sample_label\n",
    "                    break\n",
    "\n",
    "            if not label:\n",
    "                print(f\" unknown file: {filename}- skipping\")\n",
    "                continue\n",
    "\n",
    "            urls = load_urls_from_files(filepath, max_per_sample)\n",
    "\n",
    "            if urls: \n",
    "                if label in files_dict:\n",
    "                    files_dict[label].extend(urls)\n",
    "                else:\n",
    "                    files_dict[label] =urls\n",
    "\n",
    "    return files_dict\n",
    "\n",
    "# files = load_all_files(DATA_DIR, MC_DIR, max_per_sample= 1)\n",
    "files = load_all_files(DATA_DIR, MC_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES TO PROCESS\")\n",
    "print(\"=\"*70)\n",
    "total = 0\n",
    "for label, urls in files.items():\n",
    "    print(f\"{label:20s}: {len(urls):4d} files\")\n",
    "    total += len(urls)\n",
    "print(\"_\"*70)\n",
    "print(f\"{'TOTAL':20s}: {total:4d} files\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7b01052-a05a-4089-9f63-b10d305b8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_golden_json(json_input, run_periods=None):\n",
    "    \"\"\"\n",
    "    Load golden JSON from either a file path (str) or a dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(json_input, str):\n",
    "        with open(json_input, 'r') as f:\n",
    "            golden_json = json.load(f)\n",
    "    elif isinstance(json_input, dict):\n",
    "        golden_json = json_input\n",
    "    else:\n",
    "        raise TypeError(f\"Expected str or dict, got {type(json_input)}\")\n",
    "    \n",
    "    valid_lumis = {}\n",
    "    for run_str, lumi_ranges in golden_json.items():\n",
    "        run = int(run_str)\n",
    "        \n",
    "        # Filter by run periods \n",
    "        if run_periods is not None: \n",
    "            in_period = any(\n",
    "                period['run_min'] <= run <= period['run_max']\n",
    "                for period in run_periods.values()\n",
    "            )\n",
    "            if not in_period:\n",
    "                continue\n",
    "        \n",
    "        valid_lumis[run] = [tuple(lr) for lr in lumi_ranges]\n",
    "    \n",
    "    return valid_lumis\n",
    "\n",
    "\n",
    "def apply_json_mask(arrays, json_input, run_periods=None):\n",
    "\n",
    "    valid_lumis = load_golden_json(json_input, run_periods)\n",
    "    \n",
    "    runs = ak.to_numpy(arrays.run)\n",
    "    lumis = ak.to_numpy(arrays.luminosityBlock)\n",
    "    \n",
    "    mask = np. zeros(len(runs), dtype=bool)\n",
    "    \n",
    "    for run, lumi_ranges in valid_lumis.items():\n",
    "        run_mask = (runs == run)\n",
    "        \n",
    "        if not np.any(run_mask):\n",
    "            continue\n",
    "        \n",
    "        # Check lumi sections \n",
    "        run_lumis = lumis[run_mask]\n",
    "        run_lumi_mask = np.zeros(len(run_lumis), dtype=bool)\n",
    "        \n",
    "        for lumi_start, lumi_end in lumi_ranges: \n",
    "            run_lumi_mask |= (run_lumis >= lumi_start) & (run_lumis <= lumi_end)\n",
    "        \n",
    "        mask[run_mask] = run_lumi_mask\n",
    "    \n",
    "    return ak.Array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df1db6e6-5b05-4fe5-bdca-5fa626d732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 1_250_000\n",
    "\n",
    "def load_events(file_url, batch_size=1_250_000, timeout=600, max_retries=3, retry_wait=10, is_data=False):\n",
    "    columns = [\n",
    "        \"Electron_pt\", \"Electron_eta\", \"Electron_phi\", \"Electron_mass\", \n",
    "        \"Electron_mvaFall17V2Iso_WP90\", \"Electron_charge\",\n",
    "        \n",
    "        \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_mass\", \n",
    "        \"Muon_tightId\", \"Muon_charge\", \"Muon_pfRelIso04_all\",\n",
    "        \"PuppiMET_pt\", \"PuppiMET_phi\",\n",
    "        \n",
    "        \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_mass\",\n",
    "        \"Jet_btagDeepFlavB\", \"nJet\", \"Jet_jetId\", \"Jet_puId\",\n",
    "\n",
    "        \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\",\n",
    "        \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"\n",
    "    ]\n",
    "\n",
    "    if is_data:\n",
    "        columns.extend([\"run\", \"luminosityBlock\"])\n",
    "    else:\n",
    "        columns.append(\"genWeight\")\n",
    "        \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with uproot.open(file_url, timeout=timeout) as f:\n",
    "                tree = f['Events']\n",
    "                \n",
    "                for arrays in tree.iterate(columns, step_size=batch_size, library=\"ak\"):\n",
    "                    yield arrays\n",
    "                \n",
    "                return\n",
    "                \n",
    "        except (TimeoutError, OSError, IOError, ConnectionError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"      {error_type} on {file_name}\")\n",
    "                print(f\"       Retry {attempt+1}/{max_retries-1} in {retry_wait}s...\")\n",
    "                time.sleep(retry_wait)\n",
    "            else:\n",
    "                print(f\"     FAILED after {max_retries} attempts: {file_name}\")\n",
    "                print(f\"       Error: {str(e)[:100]}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            print(f\"     Unexpected error on {file_name}: {str(e)[:100]}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "469a14f0-a8c8-4147-a820-b93e9b1762ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lepton_array(arrays):\n",
    "    electrons = ak.zip({\n",
    "        \"pt\": arrays.Electron_pt,\n",
    "        \"eta\": arrays.Electron_eta,\n",
    "        \"phi\": arrays.Electron_phi,\n",
    "        \"mass\": arrays.Electron_mass,\n",
    "        \"charge\": arrays.Electron_charge,\n",
    "        \"id_pass\": arrays.Electron_mvaFall17V2Iso_WP90 == 1, \n",
    "        \"flavor\": ak.ones_like(arrays.Electron_pt) * 11\n",
    "    })\n",
    "    \n",
    "    muons = ak.zip({\n",
    "        \"pt\": arrays.Muon_pt,\n",
    "        \"eta\": arrays.Muon_eta,\n",
    "        \"phi\": arrays.Muon_phi,\n",
    "        \"mass\": arrays.Muon_mass,\n",
    "        \"charge\": arrays.Muon_charge,\n",
    "        \"id_pass\": (arrays.Muon_tightId == 1) & (arrays.Muon_pfRelIso04_all < 0.15), \n",
    "        \"flavor\": ak.ones_like(arrays.Muon_pt) * 13\n",
    "    })\n",
    "\n",
    "    return electrons, muons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b522d9e-f7c3-438a-b805-eb7d21e96d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tag_probe_events(leptons, probe_pt_lower = 10, probe_pt_upper = 50, eta_cut = 1.479):\n",
    "    \"\"\"\n",
    "    Ordered Tag & Probe:\n",
    "    - Tag   = Leading Lepton (Must pass Tight ID)\n",
    "    - Probe = Subleading Lepton (No ID check yet)\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_leptons = leptons[ak.argsort(leptons.pt, ascending=False)]\n",
    "\n",
    "    mask_2lep = ak.num(sorted_leptons) == 2\n",
    "    events_2lep = sorted_leptons[mask_2lep]\n",
    "\n",
    "    if len(events_2lep) == 0:\n",
    "        return None, None\n",
    "\n",
    "    tag_candidate = events_2lep[:, 0]   # Leading\n",
    "    probe_candidate = events_2lep[:, 1] # Subleading\n",
    "\n",
    "    # Charge\n",
    "    mask_charge = tag_candidate.charge * probe_candidate.charge < 0\n",
    "    \n",
    "    # Kinematics (Tag > 35, Probe > 10)\n",
    "    mask_pt = (tag_candidate.pt > 35) & \\\n",
    "              (probe_candidate.pt >50)\n",
    "              # (probe_candidate.pt < probe_pt_upper) & \\\n",
    "    \n",
    "    mask_eta = (abs(tag_candidate.eta) < eta_cut) & \\\n",
    "               (abs(probe_candidate.eta) < 2.5) & \\\n",
    "               (abs(probe_candidate.eta) > 1.479)\n",
    "    \n",
    "    #  Leading must pass ID\n",
    "    mask_tag_id = (tag_candidate.id_pass == True)\n",
    "\n",
    "    # 5. Final Mask\n",
    "    final_mask = mask_charge & mask_pt & mask_eta & mask_tag_id\n",
    "\n",
    "    # Return valid pairs\n",
    "    return (tag_candidate[final_mask],\n",
    "            probe_candidate[final_mask], \n",
    "            probe_pt_lower,\n",
    "            probe_pt_upper, \n",
    "           eta_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9943d57d-d4c9-4588-8f1b-b36dd257b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lepton_vector(lepton):\n",
    "    \"\"\"Create 4-vector from lepton properties \"\"\"\n",
    "    return vector.array({\n",
    "        \"pt\": lepton.pt,\n",
    "        \"eta\": lepton.eta,\n",
    "        \"phi\": lepton.phi,\n",
    "        \"mass\": lepton.mass\n",
    "    })\n",
    "\n",
    "def calculate_mll(lepton_1, lepton_2):\n",
    "    vec_1 = create_lepton_vector(lepton_1)\n",
    "    vec_2 = create_lepton_vector(lepton_2)\n",
    "\n",
    "    dilepton = vec_1 + vec_2\n",
    "\n",
    "    mll = dilepton.mass\n",
    "\n",
    "    return mll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58607b74-3a4c-469c-a31c-1aabbd417023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "\n",
    "vector.register_awkward() \n",
    "\n",
    "def tag_prob_process(golden_json_data, run_periods):\n",
    "    \"\"\"\n",
    "    Factory function for Tag & Probe Analysis.\n",
    "    Returns: label, numerator, denominator, metadata, error\n",
    "    \"\"\"\n",
    "\n",
    "    def tag_probe_processing(label, file_url, file_idx):\n",
    "        \n",
    "        count_total_probes = 0   # Denominator\n",
    "        count_passing_probes = 0 # Numerator \n",
    "        \n",
    "        meta_info = (0, 0, 0) \n",
    "        \n",
    "        file_name = file_url.split('/')[-1] \n",
    "        is_data = (label == 'Data')\n",
    "        \n",
    "        target_flavor = 'electron' \n",
    "        \n",
    "        max_file_retries = 3\n",
    "\n",
    "        for file_attempt in range(max_file_retries):\n",
    "            try:\n",
    "                #  Load Events\n",
    "                for arrays in load_events(file_url, batch_size=1_250_000, is_data=is_data):\n",
    "                    \n",
    "                    # Apply JSON Mask \n",
    "                    if is_data and golden_json_data is not None:\n",
    "                        try:\n",
    "                            json_mask = apply_json_mask(arrays, golden_json_data, run_periods=run_periods)\n",
    "                            if np.sum(json_mask) == 0: continue\n",
    "                            arrays = arrays[json_mask]\n",
    "                        except Exception as e: \n",
    "                            print(f\"Warning: JSON mask failed for {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Create Lepton Objects \n",
    "                    electrons, muons = lepton_array(arrays)\n",
    "                    \n",
    "                    # Select Flavor\n",
    "                    leptons = electrons if target_flavor == 'electron' else muons\n",
    "\n",
    "                    tags, probes, pt_low, pt_high, eta_cut = select_tag_probe_events(leptons)\n",
    "                    \n",
    "                    # Store cuts for return\n",
    "                    meta_info = (pt_low, pt_high, eta_cut)\n",
    "\n",
    "                    if tags is None or len(tags) == 0:\n",
    "                        continue\n",
    "\n",
    "                    m_ll = calculate_mll(tags, probes)\n",
    "                    \n",
    "                    z_mask = (m_ll > 60) & (m_ll < 120)\n",
    "                    \n",
    "                    # Apply Mask\n",
    "                    valid_tags = tags[z_mask]\n",
    "                    valid_probes = probes[z_mask]\n",
    "                    \n",
    "                    if len(valid_tags) == 0: \n",
    "                        continue\n",
    "\n",
    "                    # Count Events\n",
    "                    n_total = len(valid_probes)\n",
    "                    n_pass = ak.sum(valid_probes.id_pass)\n",
    "                    \n",
    "                    count_total_probes += n_total\n",
    "                    count_passing_probes += n_pass\n",
    "                \n",
    "                return label, count_passing_probes, count_total_probes, meta_info, None\n",
    "\n",
    "            except (OSError, IOError, ValueError) as e:\n",
    "                if file_attempt < max_file_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                else: \n",
    "                    return label, 0, 0, None, f\"{file_name}: Retry limit - {str(e)[:100]}\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return label, 0, 0, None, f\"{file_name}: Crash - {str(e)[:100]}\"\n",
    "\n",
    "        return label, 0, 0, None, \"Unknown loop exit\"\n",
    "\n",
    "    return tag_probe_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "902fe86f-dab2-439b-aab6-cf9050083463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TAG & PROBE PROCESSING START\n",
      "======================================================================\n",
      "\n",
      "==============================================================================================================\n",
      "SAMPLE               | FILES  |       PROBES |       PASS |      EFF |        pT RANGE |    ETA CUT\n",
      "==============================================================================================================\n",
      "DY_to_Tau_Tau        | 61     |        9,227 |      8,202 |   88.89% |       10-50 GeV |  |n|<1.479\n",
      "Data                 | 48     |          264 |        188 |   71.21% |       10-50 GeV |  |n|<1.479\n",
      "______________________________________________________________________________________________________________\n",
      "TOTAL                | 109    |        9,491 |      8,390 |   88.40% |               - |          -\n",
      "==============================================================================================================\n",
      "\n",
      "Done in 183.4s (1.68s/file)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MAIN PROCESSING \n",
    "\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dask.distributed import progress\n",
    "\n",
    "print(f\"\\n{'='*70}\\nTAG & PROBE PROCESSING START\\n{'='*70}\")\n",
    "\n",
    "golden_json_data = None\n",
    "if GOLDEN_JSON_PATH.exists():\n",
    "    with open(GOLDEN_JSON_PATH, 'r') as f:\n",
    "        golden_json_data = json.load(f)\n",
    "else:\n",
    "    print(f\"WARNING: Golden JSON not found at {GOLDEN_JSON_PATH}\")\n",
    "\n",
    "processing_task = tag_prob_process(\n",
    "    golden_json_data=golden_json_data,\n",
    "    run_periods=RUN_PERIODS_2016\n",
    ")\n",
    "\n",
    "arg_labels = []\n",
    "arg_urls = []\n",
    "arg_indices = []\n",
    "\n",
    "for label, urls in files.items():\n",
    "    for file_idx, file_url in enumerate(urls):\n",
    "        arg_labels.append(label)\n",
    "        arg_urls.append(str(file_url))\n",
    "        arg_indices.append(file_idx)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "futures = client.map(\n",
    "    processing_task,   \n",
    "    arg_labels,\n",
    "    arg_urls,\n",
    "    arg_indices,\n",
    "    retries=1\n",
    ")\n",
    "\n",
    "progress(futures)\n",
    "results = client.gather(futures)\n",
    "elapsed = time.perf_counter() - start_time\n",
    "\n",
    "final_stats = defaultdict(lambda: [0, 0, 0]) \n",
    "final_meta = {} \n",
    "errors = []\n",
    "\n",
    "for label, n_pass, n_total, meta, error in results:\n",
    "    if error:\n",
    "        errors.append((label, error))\n",
    "    else:\n",
    "        stats = final_stats[label]\n",
    "        stats[0] += n_pass   \n",
    "        stats[1] += n_total  \n",
    "        stats[2] += 1        \n",
    "        \n",
    "        if label not in final_meta and meta is not None:\n",
    "            final_meta[label] = meta\n",
    "\n",
    "print(f\"\\n{'='*110}\")\n",
    "print(f\"{'SAMPLE':<20} | {'FILES':<6} | {'PROBES':>12} | {'PASS':>10} | {'EFF':>8} | {'pT RANGE':>15} | {'ETA CUT':>10}\")\n",
    "print(\"=\"*110)\n",
    "\n",
    "tot_pass = tot_total = tot_files = 0\n",
    "\n",
    "for label, (n_pass, n_total, n_files) in sorted(final_stats.items()):\n",
    "    eff = (n_pass / n_total * 100) if n_total > 0 else 0.0\n",
    "    \n",
    "    if label in final_meta:\n",
    "        pt_min, pt_max, eta_cut = final_meta[label]\n",
    "        pt_str = f\"{pt_min}-{pt_max} GeV\"\n",
    "        eta_str = f\"|n|<{eta_cut}\"\n",
    "    else:\n",
    "        pt_str = \"N/A\"\n",
    "        eta_str = \"N/A\"\n",
    "\n",
    "    print(f\"{label:<20} | {n_files:<6} | {n_total:>12,} | {n_pass:>10,} | {eff:>7.2f}% | {pt_str:>15} | {eta_str:>10}\")\n",
    "    \n",
    "    tot_pass += n_pass\n",
    "    tot_total += n_total\n",
    "    tot_files += n_files\n",
    "\n",
    "print(\"_\"*110)\n",
    "tot_eff = (tot_pass / tot_total * 100) if tot_total > 0 else 0.0\n",
    "print(f\"{'TOTAL':<20} | {tot_files:<6} | {tot_total:>12,} | {tot_pass:>10,} | {tot_eff:>7.2f}% | {'-':>15} | {'-':>10}\")\n",
    "print(f\"{'='*110}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n[!] Encountered {len(errors)} errors:\")\n",
    "    for label, err in errors[:5]: print(f\"  - {label}: {err}\")\n",
    "\n",
    "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(arg_urls):.2f}s/file)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b64ffa-d4e0-4506-8f53-e1ed01e3dc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73578c-7a03-470c-b94e-27b5b8677122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3073f-6a63-4606-b528-eb993f198b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
