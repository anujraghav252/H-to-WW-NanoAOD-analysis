{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ad64f7-ba57-4d4e-9ff3-f108b1589e06",
   "metadata": {},
   "source": [
    "## This notebook is for Data and MC corrections:\n",
    "1. Trigger Efficiencies\n",
    "2. Leptom effeciencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef4bad-a51d-429e-b234-b50da3f8796c",
   "metadata": {},
   "source": [
    "## TRIGGER EFFICIENCY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2b291-f93e-46c1-b8df-98f8956f888c",
   "metadata": {},
   "source": [
    "### Only for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe41238-7d38-45ca-9dc0-25a559250ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc \n",
    "import psutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "print(\"All imports added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a474e7-c837-4485-aaa4-805cf6510a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-89610e83-f60c-11f0-87de-86e564a09735</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/anujraghav.physics@gmail.com/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8039d2c6-0e2a-4589-815c-b7f137ad52d9</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://192.168.161.139:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.161.139:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ee6dfb-8bbd-4c84-bf52-7a51c11e245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR:         /home/cms-jovyan\n",
      "PROJECT_DIR:     /home/cms-jovyan/H-to-WW-NanoAOD-analysis\n",
      "DATA_DIR:        /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/DATA\n",
      "MC_DIR:          /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/MC_samples\n",
      "AUX_DIR:         /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files\n",
      "GOLDEN_JSON:      /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\n",
      "JSON exists:     True\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = Path(os.environ.get(\"HOME\", \"/home/cms-jovyan\"))\n",
    "PROJECT_NAME = \"H-to-WW-NanoAOD-analysis\"\n",
    "\n",
    "PROJECT_DIR = HOME_DIR / PROJECT_NAME\n",
    "DATASETS_DIR = PROJECT_DIR / \"Datasets\"\n",
    "DATA_DIR = DATASETS_DIR / \"DATA\"\n",
    "MC_DIR = DATASETS_DIR / \"MC_samples\"\n",
    "AUX_DIR = PROJECT_DIR / \"Auxillary_files\"\n",
    "\n",
    "GOLDEN_JSON_PATH = AUX_DIR / \"Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\"\n",
    "\n",
    "RUN_PERIODS_2016 = {\n",
    "    \"Run2016G\": {\"run_min\": 278820, \"run_max\": 280385},\n",
    "    \"Run2016H\": {\"run_min\": 280919, \"run_max\": 284044}\n",
    "}\n",
    "\n",
    "print(f\"HOME_DIR:         {HOME_DIR}\")\n",
    "print(f\"PROJECT_DIR:     {PROJECT_DIR}\")\n",
    "print(f\"DATA_DIR:        {DATA_DIR}\")\n",
    "print(f\"MC_DIR:          {MC_DIR}\")\n",
    "print(f\"AUX_DIR:         {AUX_DIR}\")\n",
    "print(f\"GOLDEN_JSON:      {GOLDEN_JSON_PATH}\")\n",
    "print(f\"JSON exists:     {GOLDEN_JSON_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef0c6fb-d197-4752-8abe-62367b7612be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unknown file: VG.txt- skipping\n",
      " unknown file: Higgs.txt- skipping\n",
      " unknown file: WW.txt- skipping\n",
      " unknown file: Fakes.txt- skipping\n",
      " unknown file: VZ.txt- skipping\n",
      " unknown file: DYtoLL.txt- skipping\n",
      " unknown file: ggWW.txt- skipping\n",
      " unknown file: Top.txt- skipping\n",
      "\n",
      "======================================================================\n",
      "FILES TO PROCESS\n",
      "======================================================================\n",
      "Data                :    1 files\n",
      "______________________________________________________________________\n",
      "TOTAL               :    1 files\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_MAPPING = {\n",
    "    'data' : \"Data\",\n",
    "    # 'dytoll' : \"DY_to_Tau_Tau\",\n",
    "}\n",
    "\n",
    "def load_urls_from_files(filepath, max_files = None):\n",
    "    urls = []\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        return urls\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('root://'):\n",
    "                urls.append(line)\n",
    "                if max_files and len(urls) >= max_files:\n",
    "                    break\n",
    "    return urls\n",
    "\n",
    "def load_all_files(data_dir, mc_dir, max_per_sample = None):\n",
    "\n",
    "    files_dict = {}\n",
    "\n",
    "    for directory in [data_dir, mc_dir]:\n",
    "        if not os.path.exists(directory):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            filename_lower = filename.lower().replace('.txt', '')\n",
    "\n",
    "            label = None\n",
    "\n",
    "            for pattern, sample_label in SAMPLE_MAPPING.items():\n",
    "                if pattern in filename_lower:\n",
    "                    label = sample_label\n",
    "                    break\n",
    "\n",
    "            if not label:\n",
    "                print(f\" unknown file: {filename}- skipping\")\n",
    "                continue\n",
    "\n",
    "            urls = load_urls_from_files(filepath, max_per_sample)\n",
    "\n",
    "            if urls: \n",
    "                if label in files_dict:\n",
    "                    files_dict[label].extend(urls)\n",
    "                else:\n",
    "                    files_dict[label] =urls\n",
    "\n",
    "    return files_dict\n",
    "\n",
    "files = load_all_files(DATA_DIR, MC_DIR, max_per_sample= 1)\n",
    "# files = load_all_files(DATA_DIR, MC_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES TO PROCESS\")\n",
    "print(\"=\"*70)\n",
    "total = 0\n",
    "for label, urls in files.items():\n",
    "    print(f\"{label:20s}: {len(urls):4d} files\")\n",
    "    total += len(urls)\n",
    "print(\"_\"*70)\n",
    "print(f\"{'TOTAL':20s}: {total:4d} files\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33e641c-e346-4fe3-aa71-c7a9443b324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_golden_json(json_input, run_periods=None):\n",
    "    \"\"\"\n",
    "    Load golden JSON from either a file path (str) or a dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(json_input, str):\n",
    "        with open(json_input, 'r') as f:\n",
    "            golden_json = json.load(f)\n",
    "    elif isinstance(json_input, dict):\n",
    "        golden_json = json_input\n",
    "    else:\n",
    "        raise TypeError(f\"Expected str or dict, got {type(json_input)}\")\n",
    "    \n",
    "    valid_lumis = {}\n",
    "    for run_str, lumi_ranges in golden_json.items():\n",
    "        run = int(run_str)\n",
    "        \n",
    "        # Filter by run periods \n",
    "        if run_periods is not None: \n",
    "            in_period = any(\n",
    "                period['run_min'] <= run <= period['run_max']\n",
    "                for period in run_periods.values()\n",
    "            )\n",
    "            if not in_period:\n",
    "                continue\n",
    "        \n",
    "        valid_lumis[run] = [tuple(lr) for lr in lumi_ranges]\n",
    "    \n",
    "    return valid_lumis\n",
    "\n",
    "\n",
    "def apply_json_mask(arrays, json_input, run_periods=None):\n",
    "\n",
    "    valid_lumis = load_golden_json(json_input, run_periods)\n",
    "    \n",
    "    runs = ak.to_numpy(arrays.run)\n",
    "    lumis = ak.to_numpy(arrays.luminosityBlock)\n",
    "    \n",
    "    mask = np. zeros(len(runs), dtype=bool)\n",
    "    \n",
    "    for run, lumi_ranges in valid_lumis.items():\n",
    "        run_mask = (runs == run)\n",
    "        \n",
    "        if not np.any(run_mask):\n",
    "            continue\n",
    "        \n",
    "        # Check lumi sections \n",
    "        run_lumis = lumis[run_mask]\n",
    "        run_lumi_mask = np.zeros(len(run_lumis), dtype=bool)\n",
    "        \n",
    "        for lumi_start, lumi_end in lumi_ranges: \n",
    "            run_lumi_mask |= (run_lumis >= lumi_start) & (run_lumis <= lumi_end)\n",
    "        \n",
    "        mask[run_mask] = run_lumi_mask\n",
    "    \n",
    "    return ak.Array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48f4f36-672e-4679-8a22-1c5556a406ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get name of the branch required for trigger efficiency \n",
    "\n",
    "# # DATA\n",
    "# root_file_name = \"root://eospublic.cern.ch//eos/opendata/cms/Run2016G/MuonEG/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/120000/2ADBED61-A06A-D64B-BE90-E9B267D15700.root\"\n",
    "\n",
    "# #  MC \n",
    "\n",
    "# # file_url = \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/DYJetsToLL_M-50_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/40000/14B6A8AE-C9FE-D744-80A4-DDE5D008C1CD.root\"\n",
    "\n",
    "# with uproot.open(root_file_name) as file:\n",
    "#         # Access the Events tree\n",
    "#         if \"Events\" not in file:\n",
    "#             print(\"Error: 'Events' tree not found in file.\")\n",
    "#         else:\n",
    "#             tree = file[\"Events\"]\n",
    "#             branches = tree.keys()\n",
    "            \n",
    "#             print(f\"\\nConnection Successful!\")\n",
    "#             print(f\"Total Branches found: {len(branches)}\")\n",
    "#             print(\"=\" * 60)\n",
    "            \n",
    "#             # Print all branches alphabetically\n",
    "#             for branch in sorted(branches):\n",
    "#                 if \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\" in branch or \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"  in branch:\n",
    "#                     print(branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5b221e-9c79-4dfe-8f9b-87b2568ec72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 1_250_000\n",
    "\n",
    "def load_events(file_url, batch_size=1_250_000, timeout=600, max_retries=3, retry_wait=10, is_data=False):\n",
    "    columns = [\n",
    "        \"Electron_pt\", \"Electron_eta\", \"Electron_phi\", \"Electron_mass\", \n",
    "        \"Electron_mvaFall17V2Iso_WP90\", \"Electron_charge\",\n",
    "        \n",
    "        \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_mass\", \n",
    "        \"Muon_tightId\", \"Muon_charge\", \"Muon_pfRelIso04_all\",\n",
    "        \"PuppiMET_pt\", \"PuppiMET_phi\",\n",
    "        \n",
    "        \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_mass\",\n",
    "        \"Jet_btagDeepFlavB\", \"nJet\", \"Jet_jetId\", \"Jet_puId\",\n",
    "\n",
    "        \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\",\n",
    "        \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"\n",
    "    ]\n",
    "\n",
    "    if is_data:\n",
    "        columns.extend([\"run\", \"luminosityBlock\"])\n",
    "    else:\n",
    "        columns.append(\"genWeight\")\n",
    "        \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with uproot.open(file_url, timeout=timeout) as f:\n",
    "                tree = f['Events']\n",
    "                \n",
    "                for arrays in tree.iterate(columns, step_size=batch_size, library=\"ak\"):\n",
    "                    yield arrays\n",
    "                \n",
    "                return\n",
    "                \n",
    "        except (TimeoutError, OSError, IOError, ConnectionError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"      {error_type} on {file_name}\")\n",
    "                print(f\"       Retry {attempt+1}/{max_retries-1} in {retry_wait}s...\")\n",
    "                time.sleep(retry_wait)\n",
    "            else:\n",
    "                print(f\"     FAILED after {max_retries} attempts: {file_name}\")\n",
    "                print(f\"       Error: {str(e)[:100]}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            print(f\"     Unexpected error on {file_name}: {str(e)[:100]}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2b65a-6c9a-40d2-99d7-b13ddbaae4f6",
   "metadata": {},
   "source": [
    "## TRIGGER PART\n",
    "\n",
    "Trigger efficiency = $\\frac{denominator + Trigger cut}{\\#\\ of\\ events\\ after\\ passing\\ preselection}$\n",
    "\n",
    "> Preselection inlcudes:\n",
    "> 1. 2 leptons\n",
    "> 2. lepton ID (Electron \\& Muon)\n",
    "> 3. |$\\eta$| < 2.5\n",
    "> 4. pT requirement: lead >25 and sublead > 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319cc247-1c78-48cd-9551-182c320cedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tight_leptons(arrays):\n",
    "    tight_electron_mask = arrays.Electron_mvaFall17V2Iso_WP90 == 1\n",
    "    tight_muon_mask = (arrays.Muon_tightId == 1) & (arrays.Muon_pfRelIso04_all < 0.15)\n",
    "    \n",
    "    tight_electrons = ak.zip({\n",
    "        \"pt\": arrays.Electron_pt[tight_electron_mask],\n",
    "        \"eta\": arrays.Electron_eta[tight_electron_mask],\n",
    "        \"phi\": arrays.Electron_phi[tight_electron_mask],\n",
    "        \"mass\": arrays.Electron_mass[tight_electron_mask],\n",
    "        \"charge\": arrays.Electron_charge[tight_electron_mask],\n",
    "        \"flavor\": ak.values_astype(ak.ones_like(arrays.Electron_pt[tight_electron_mask]) * 11, \"int32\")\n",
    "    })\n",
    "    \n",
    "    tight_muons = ak.zip({\n",
    "        \"pt\": arrays.Muon_pt[tight_muon_mask],\n",
    "        \"eta\": arrays.Muon_eta[tight_muon_mask],\n",
    "        \"phi\": arrays.Muon_phi[tight_muon_mask],\n",
    "        \"mass\": arrays.Muon_mass[tight_muon_mask],\n",
    "        \"charge\": arrays.Muon_charge[tight_muon_mask],\n",
    "        \"flavor\": ak.values_astype(ak.ones_like(arrays.Muon_pt[tight_muon_mask]) * 13, \"int32\")\n",
    "    })\n",
    "    \n",
    "    tight_leptons = ak.concatenate([tight_electrons, tight_muons], axis=1)\n",
    "    return tight_leptons\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5992dcd7-a4a4-4b7f-99e3-64f10c33d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_emu_events(tight_leptons, arrays):\n",
    "    # Sort leptons\n",
    "    sorted_leptons = tight_leptons[ak.argsort(tight_leptons.pt, ascending=False)]\n",
    "\n",
    "    mask_2lep = ak.num(sorted_leptons) == 2\n",
    "    \n",
    "    events_2lep = sorted_leptons[mask_2lep]\n",
    "    arrays_2lep = arrays[mask_2lep]  # Keeps HLT branches aligned\n",
    "\n",
    "    if len(events_2lep) == 0:\n",
    "        return 0, 0, None\n",
    "\n",
    "    # Kinematic Cuts \n",
    "    leading = events_2lep[:, 0]\n",
    "    subleading = events_2lep[:, 1]\n",
    "\n",
    "    mask_flavor = ((leading.flavor == 13) & (subleading.flavor == 11)) | \\\n",
    "                  ((leading.flavor == 11) & (subleading.flavor == 13))\n",
    "    mask_charge = leading.charge * subleading.charge < 0\n",
    "    mask_pt = (leading.pt > 25) & (subleading.pt > 13)\n",
    "    mask_eta = (abs(leading.eta) < 2.5) & (abs(subleading.eta) < 2.5)\n",
    "\n",
    "    # E-Mu Selected mask\n",
    "    mask_emu_kinematics = mask_flavor & mask_charge & mask_pt & mask_eta\n",
    "\n",
    "    # Trigger (HLT) Cut\n",
    "    # apply this to 'arrays_2lep' which matches 'events_2lep' size\n",
    "    mask_hlt = (arrays_2lep.HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ == 1) | \\\n",
    "               (arrays_2lep.HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ == 1)\n",
    "\n",
    "    #  Final Masks\n",
    "    # Events passing ONLY kinematics\n",
    "    events_passing_emu = events_2lep[mask_emu_kinematics]\n",
    "    \n",
    "    # Events passing Kinematics AND HLT\n",
    "    final_mask = mask_emu_kinematics & mask_hlt\n",
    "    events_passing_all = events_2lep[final_mask]\n",
    "\n",
    "    # Return counts and the final objects\n",
    "    n_emu = len(events_passing_emu)\n",
    "    n_final = len(events_passing_all)\n",
    "    \n",
    "    return n_emu, n_final, events_passing_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f302e9b4-f269-49bc-bdc1-9712b80fc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "def make_processor(golden_json_data, run_periods):\n",
    "    \"\"\"\n",
    "    Factory function that returns a worker function with \n",
    "    JSON data and Run Periods baked in (Closure Pattern).\n",
    "    \"\"\"\n",
    "\n",
    "    def processing_file(label, file_url, file_idx):\n",
    "        \n",
    "        # Initialize Counters\n",
    "        count_emu_kinematics = 0\n",
    "        count_emu_hlt = 0\n",
    "        \n",
    "        file_name = file_url.split('/')[-1] \n",
    "        is_data = (label == 'Data')\n",
    "        \n",
    "        max_file_retries = 3\n",
    "\n",
    "        for file_attempt in range(max_file_retries):\n",
    "            try:\n",
    "                # Load Events\n",
    "                for arrays in load_events(file_url, batch_size=1_250_000, is_data=is_data):\n",
    "                    \n",
    "                    #  Apply JSON Mask to Data\n",
    "                    if is_data and golden_json_data is not None:\n",
    "                        try:\n",
    "                            json_mask = apply_json_mask(arrays, golden_json_data, run_periods=run_periods)\n",
    "                            if np.sum(json_mask) == 0: continue\n",
    "                            arrays = arrays[json_mask]\n",
    "                        except Exception as e: \n",
    "                            print(f\"Warning: JSON mask failed for {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Object Selection\n",
    "                    tight_leptons = select_tight_leptons(arrays)\n",
    "                    \n",
    "                    # Event Selection (Kinematics + HLT)\n",
    "                    n_emu, n_hlt, _ = select_emu_events(tight_leptons, arrays)\n",
    "                    \n",
    "                    #  Accumulate\n",
    "                    count_emu_kinematics += n_emu\n",
    "                    count_emu_hlt += n_hlt\n",
    "                \n",
    "                # Success\n",
    "                return label, count_emu_kinematics, count_emu_hlt, None\n",
    "\n",
    "            except (OSError, IOError, ValueError) as e:\n",
    "                if file_attempt < max_file_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                else: \n",
    "                    return label, 0, 0, f\"{file_name}: Failed after retries - {str(e)[:100]}\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return label, 0, 0, f\"{file_name}: Unexpected error - {str(e)[:100]}\"\n",
    "\n",
    "        return label, 0, 0, \"Unknown loop exit\"\n",
    "\n",
    "    # Return the inner function\n",
    "    return processing_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f06d71ba-5adb-426f-8282-5d399fe5b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRIGGER EFFICIENCY PROCESSING START\n",
      "======================================================================\n",
      "Preparing file lists...\n",
      "  Data: Validation enabled (1 files)\n",
      "\n",
      "Submitting 1 files to the cluster...\n",
      "\n",
      "======================================================================\n",
      "SAMPLE               | FILES    |     KINEMATICS |     HLT PASS |   TRIG EFF\n",
      "======================================================================\n",
      "Data                 | 1        |          9,635 |        7,935 |     82.36%\n",
      "______________________________________________________________________\n",
      "TOTAL                | 1        |          9,635 |        7,935 |     82.36%\n",
      "======================================================================\n",
      "\n",
      "Done in 50.6s (50.61s/file)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MAIN PROCESSING (Trigger Efficiency)\n",
    "\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dask.distributed import progress\n",
    "\n",
    "print(f\"\\n{'='*70}\\nTRIGGER EFFICIENCY PROCESSING START\\n{'='*70}\")\n",
    "\n",
    "golden_json_data = None\n",
    "if GOLDEN_JSON_PATH.exists():\n",
    "    # print(f\"Reading Golden JSON: {GOLDEN_JSON_PATH.name}\")\n",
    "    with open(GOLDEN_JSON_PATH, 'r') as f:\n",
    "        golden_json_data = json.load(f)\n",
    "    # print(f\"  Loaded {len(golden_json_data)} runs into memory\\n\")\n",
    "else:\n",
    "    print(f\"WARNING: Golden JSON not found at {GOLDEN_JSON_PATH}\")\n",
    "\n",
    "processing_task = make_processor(\n",
    "    golden_json_data=golden_json_data,\n",
    "    run_periods=RUN_PERIODS_2016\n",
    ")\n",
    "\n",
    "arg_labels = []\n",
    "arg_urls = []\n",
    "arg_indices = []\n",
    "\n",
    "print(\"Preparing file lists...\")\n",
    "\n",
    "for label, urls in files.items():\n",
    "    is_data = (label == 'Data')\n",
    "    \n",
    "    if is_data:\n",
    "        if golden_json_data is not None:\n",
    "             print(f\"  {label}: Validation enabled ({len(urls)} files)\")\n",
    "    \n",
    "    for file_idx, file_url in enumerate(urls):\n",
    "        arg_labels.append(label)\n",
    "        arg_urls.append(str(file_url))\n",
    "        arg_indices.append(file_idx)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "print(f\"\\nSubmitting {len(arg_urls)} files to the cluster...\")\n",
    "\n",
    "futures = client.map(\n",
    "    processing_task,    \n",
    "    arg_labels,\n",
    "    arg_urls,\n",
    "    arg_indices,\n",
    "    retries=1\n",
    ")\n",
    "\n",
    "progress(futures)\n",
    "results = client.gather(futures)\n",
    "elapsed = time.perf_counter() - start_time\n",
    "\n",
    "final_stats = defaultdict(lambda: [0, 0, 0]) \n",
    "errors = []\n",
    "\n",
    "for label, n_kinematics, n_hlt, error in results:\n",
    "    if error:\n",
    "        errors.append((label, error))\n",
    "    else:\n",
    "        stats = final_stats[label]\n",
    "        stats[0] += n_kinematics # Denominator (Events passing cuts)\n",
    "        stats[1] += n_hlt        # Numerator (Events passing cuts + HLT)\n",
    "        stats[2] += 1            # File count\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'SAMPLE':<20} | {'FILES':<8} | {'KINEMATICS':>14} | {'HLT PASS':>12} | {'TRIG EFF':>10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tot_kinematics = tot_hlt = tot_files = 0\n",
    "\n",
    "for label, (n_kinematics, n_hlt, n_files) in sorted(final_stats.items()):\n",
    "    # Efficiency = (HLT Pass / Kinematics Selection)\n",
    "    eff = (n_hlt / n_kinematics * 100) if n_kinematics > 0 else 0.0\n",
    "    \n",
    "    print(f\"{label:<20} | {n_files:<8} | {n_kinematics:>14,} | {n_hlt:>12,} | {eff:>9.2f}%\")\n",
    "    \n",
    "    tot_kinematics += n_kinematics\n",
    "    tot_hlt += n_hlt\n",
    "    tot_files += n_files\n",
    "\n",
    "print(\"_\"*70)\n",
    "tot_eff = (tot_hlt / tot_kinematics * 100) if tot_kinematics > 0 else 0.0\n",
    "print(f\"{'TOTAL':<20} | {tot_files:<8} | {tot_kinematics:>14,} | {tot_hlt:>12,} | {tot_eff:>9.2f}%\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n[!] Encountered {len(errors)} errors:\")\n",
    "    for label, err in errors[:5]: print(f\"  - {label}: {err}\")\n",
    "    if len(errors) > 5: print(f\"  ... and {len(errors)-5} more.\")\n",
    "\n",
    "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(arg_urls):.2f}s/file)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0681e3-7351-40ad-8fc2-80da651e95a6",
   "metadata": {},
   "source": [
    "## Lepton efficiency-- Tag and probe method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32ecc402-5dfb-4e18-bbaf-01551d1a53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lepton_array(arrays):\n",
    "    electrons = ak.zip({\n",
    "        \"pt\": arrays.Electron_pt,\n",
    "        \"eta\": arrays.Electron_eta,\n",
    "        \"phi\": arrays.Electron_phi,\n",
    "        \"mass\": arrays.Electron_mass,\n",
    "        \"charge\": arrays.Electron_charge,\n",
    "        \"id_pass\": arrays.Electron_mvaFall17V2Iso_WP90 == 1, \n",
    "        \"flavor\": ak.ones_like(arrays.Electron_pt) * 11\n",
    "    })\n",
    "    \n",
    "    muons = ak.zip({\n",
    "        \"pt\": arrays.Muon_pt,\n",
    "        \"eta\": arrays.Muon_eta,\n",
    "        \"phi\": arrays.Muon_phi,\n",
    "        \"mass\": arrays.Muon_mass,\n",
    "        \"charge\": arrays.Muon_charge,\n",
    "        \"id_pass\": (arrays.Muon_tightId == 1) & (arrays.Muon_pfRelIso04_all < 0.15), \n",
    "        \"flavor\": ak.ones_like(arrays.Muon_pt) * 13\n",
    "    })\n",
    "\n",
    "    return electrons, muons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd18efb5-4b2b-453e-afe8-13243329e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tag_probe_events(leptons, probe_pt_lower = 10, probe_pt_upper = 50):\n",
    "    \"\"\"\n",
    "    Ordered Tag & Probe:\n",
    "    - Tag   = Leading Lepton (Must pass Tight ID)\n",
    "    - Probe = Subleading Lepton (No ID check yet)\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_leptons = leptons[ak.argsort(leptons.pt, ascending=False)]\n",
    "\n",
    "    mask_2lep = ak.num(sorted_leptons) == 2\n",
    "    events_2lep = sorted_leptons[mask_2lep]\n",
    "\n",
    "    if len(events_2lep) == 0:\n",
    "        return None, None\n",
    "\n",
    "    tag_candidate = events_2lep[:, 0]   # Leading\n",
    "    probe_candidate = events_2lep[:, 1] # Subleading\n",
    "\n",
    "    # Charge\n",
    "    mask_charge = tag_candidate.charge * probe_candidate.charge < 0\n",
    "    \n",
    "    # Kinematics (Tag > 35, Probe > 10)\n",
    "    mask_pt = (tag_candidate.pt > 35) & (probe_candidate.pt < probe_pt_upper) & (probe_candidate.pt >probe_pt_lower)\n",
    "    mask_eta = (abs(tag_candidate.eta) < 2.5) & (abs(probe_candidate.eta) < 2.5)\n",
    "    \n",
    "    #  Leading must pass ID\n",
    "    mask_tag_id = (tag_candidate.id_pass == True)\n",
    "\n",
    "    # 5. Final Mask\n",
    "    final_mask = mask_charge & mask_pt & mask_eta & mask_tag_id\n",
    "\n",
    "    # Return valid pairs\n",
    "    return tag_candidate[final_mask], probe_candidate[final_mask], probe_pt_lower, probe_pt_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7214d6fe-7330-4f26-bb5f-545357f3297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lepton_vector(lepton):\n",
    "    \"\"\"Create 4-vector from lepton properties \"\"\"\n",
    "    return vector.array({\n",
    "        \"pt\": lepton.pt,\n",
    "        \"eta\": lepton.eta,\n",
    "        \"phi\": lepton.phi,\n",
    "        \"mass\": lepton.mass\n",
    "    })\n",
    "\n",
    "def calculate_mll(lepton_1, lepton_2):\n",
    "    vec_1 = create_lepton_vector(lepton_1)\n",
    "    vec_2 = create_lepton_vector(lepton_2)\n",
    "\n",
    "    dilepton = vec_1 + vec_2\n",
    "\n",
    "    mll = dilepton.mass\n",
    "\n",
    "    return mll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74660261-9db4-417a-8229-98a5ab06e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import vector\n",
    "\n",
    "vector.register_awkward() \n",
    "\n",
    "def tag_prob_process(golden_json_data, run_periods):\n",
    "    \"\"\"\n",
    "    Factory function for Tag & Probe Analysis.\n",
    "    Returns: label, numerator (passing probes), denominator (total probes), error\n",
    "    \"\"\"\n",
    "\n",
    "    def tag_probe_processing(label, file_url, file_idx):\n",
    "        \n",
    "        count_total_probes = 0   # Denominator\n",
    "        count_passing_probes = 0 # Numerator \n",
    "        \n",
    "        file_name = file_url.split('/')[-1] \n",
    "        is_data = (label == 'Data')\n",
    "        \n",
    "        target_flavor = 'electron' \n",
    "        \n",
    "        max_file_retries = 3\n",
    "\n",
    "        for file_attempt in range(max_file_retries):\n",
    "            try:\n",
    "                #  Load Events\n",
    "                for arrays in load_events(file_url, batch_size=1_250_000, is_data=is_data):\n",
    "                    \n",
    "                    # Apply JSON Mask \n",
    "                    if is_data and golden_json_data is not None:\n",
    "                        try:\n",
    "                            json_mask = apply_json_mask(arrays, golden_json_data, run_periods=run_periods)\n",
    "                            if np.sum(json_mask) == 0: continue\n",
    "                            arrays = arrays[json_mask]\n",
    "                        except Exception as e: \n",
    "                            print(f\"Warning: JSON mask failed for {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Create Lepton Objects \n",
    "                    electrons, muons = lepton_array(arrays)\n",
    "                    \n",
    "                    # Select Flavor\n",
    "                    leptons = electrons if target_flavor == 'electron' else muons\n",
    "\n",
    "                    # 4. Tag & Probe Selection\n",
    "                    tags, probes, pt_lower, pt_upper = select_tag_probe_events(leptons)\n",
    "\n",
    "                    \n",
    "                    print(f\"For pT range {pt_lower} to {pt_upper} GeV\")\n",
    "\n",
    "                    if tags is None or len(tags) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # m_ll = (tags + probes).mass\n",
    "                    m_ll = calculate_mll(tags, probes)\n",
    "                    \n",
    "                    z_mask = (m_ll > 60) & (m_ll < 120)\n",
    "                    \n",
    "                    # Apply Mask\n",
    "                    valid_tags = tags[z_mask]\n",
    "                    valid_probes = probes[z_mask]\n",
    "\n",
    "                    \n",
    "                    if len(valid_tags) == 0: \n",
    "                        continue\n",
    "\n",
    "                    # Count Events\n",
    "                    # Denominator\n",
    "                    n_total = len(valid_probes)\n",
    "                    \n",
    "                    # Numerator: \n",
    "                    n_pass = ak.sum(valid_probes.id_pass)\n",
    "                    \n",
    "                    count_total_probes += n_total\n",
    "                    count_passing_probes += n_pass\n",
    "                \n",
    "                # Success \n",
    "                return label, count_passing_probes, count_total_probes, None\n",
    "\n",
    "            except (OSError, IOError, ValueError) as e:\n",
    "                if file_attempt < max_file_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                else: \n",
    "                    return label, 0, 0, f\"{file_name}: Retry limit - {str(e)[:100]}\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return label, 0, 0, f\"{file_name}: Crash - {str(e)[:100]}\"\n",
    "\n",
    "        return label, 0, 0, \"Unknown loop exit\"\n",
    "\n",
    "    return tag_probe_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a33e3dfa-2987-414f-b3a1-41ac4cb197b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TAG & PROBE PROCESSING START\n",
      "======================================================================\n",
      "Preparing file lists...\n",
      "\n",
      "==========================================================================================\n",
      "SAMPLE               | FILES    |   TOTAL PROBES |   PASSING ID | EFFICIENCY\n",
      "==========================================================================================\n",
      "Data                 | 48       |         51,046 |       25,154 |     49.28%\n",
      "__________________________________________________________________________________________\n",
      "TOTAL                | 48       |         51,046 |       25,154 |     49.28%\n",
      "==========================================================================================\n",
      "\n",
      "Done in 161.6s (3.37s/file)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MAIN PROCESSING \n",
    "\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dask.distributed import progress\n",
    "\n",
    "print(f\"\\n{'='*70}\\nTAG & PROBE PROCESSING START\\n{'='*70}\")\n",
    "\n",
    "golden_json_data = None\n",
    "if GOLDEN_JSON_PATH.exists():\n",
    "    # print(f\"Reading Golden JSON: {GOLDEN_JSON_PATH.name}\")\n",
    "    with open(GOLDEN_JSON_PATH, 'r') as f:\n",
    "        golden_json_data = json.load(f)\n",
    "    # print(f\"  Loaded {len(golden_json_data)} runs into memory\\n\")\n",
    "else:\n",
    "    print(f\"WARNING: Golden JSON not found at {GOLDEN_JSON_PATH}\")\n",
    "\n",
    "processing_task = tag_prob_process(\n",
    "    golden_json_data=golden_json_data,\n",
    "    run_periods=RUN_PERIODS_2016\n",
    ")\n",
    "\n",
    "arg_labels = []\n",
    "arg_urls = []\n",
    "arg_indices = []\n",
    "\n",
    "# print(\"Preparing file lists...\")\n",
    "\n",
    "for label, urls in files.items():\n",
    "    is_data = (label == 'Data')\n",
    "    \n",
    "    # if is_data:\n",
    "    #     if golden_json_data is not None:\n",
    "             # print(f\"  {label}: Validation enabled ({len(urls)} files)\")\n",
    "    \n",
    "    for file_idx, file_url in enumerate(urls):\n",
    "        arg_labels.append(label)\n",
    "        arg_urls.append(str(file_url))\n",
    "        arg_indices.append(file_idx)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# print(f\"\\nSubmitting {len(arg_urls)} files to the cluster...\")\n",
    "\n",
    "futures = client.map(\n",
    "    processing_task,   \n",
    "    arg_labels,\n",
    "    arg_urls,\n",
    "    arg_indices,\n",
    "    retries=1\n",
    ")\n",
    "\n",
    "progress(futures)\n",
    "results = client.gather(futures)\n",
    "elapsed = time.perf_counter() - start_time\n",
    "\n",
    "final_stats = defaultdict(lambda: [0, 0, 0]) \n",
    "errors = []\n",
    "\n",
    "for label, n_pass, n_total, error in results:\n",
    "    if error:\n",
    "        errors.append((label, error))\n",
    "    else:\n",
    "        stats = final_stats[label]\n",
    "        stats[0] += n_pass   # Numerator (Passing ID)\n",
    "        stats[1] += n_total  # Denominator (All Probes)\n",
    "        stats[2] += 1        # File count\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"{'SAMPLE':<20} | {'FILES':<8} | {'TOTAL PROBES':>14} | {'PASSING ID':>12} | {'EFFICIENCY':>10}\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "tot_pass = tot_total = tot_files = 0\n",
    "\n",
    "for label, (n_pass, n_total, n_files) in sorted(final_stats.items()):\n",
    "    eff = (n_pass / n_total * 100) if n_total > 0 else 0.0\n",
    "    print(f\"{label:<20} | {n_files:<8} | {n_total:>14,} | {n_pass:>12,} | {eff:>9.2f}%\")\n",
    "    tot_pass += n_pass\n",
    "    tot_total += n_total\n",
    "    tot_files += n_files\n",
    "\n",
    "print(\"_\"*90)\n",
    "tot_eff = (tot_pass / tot_total * 100) if tot_total > 0 else 0.0\n",
    "print(f\"{'TOTAL':<20} | {tot_files:<8} | {tot_total:>14,} | {tot_pass:>12,} | {tot_eff:>9.2f}%\")\n",
    "print(f\"{'='*90}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n[!] Encountered {len(errors)} errors:\")\n",
    "    for label, err in errors[:5]: print(f\"  - {label}: {err}\")\n",
    "    if len(errors) > 5: print(f\"  ... and {len(errors)-5} more.\")\n",
    "\n",
    "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(arg_urls):.2f}s/file)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd587be8-9f43-4c75-9040-29e95534f36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
