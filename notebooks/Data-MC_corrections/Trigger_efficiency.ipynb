{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb722eb6-b22e-4069-a74d-9205e49b174f",
   "metadata": {},
   "source": [
    "# Trigger Efficiency Measurement for Dilepton H→WW Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook measures the trigger efficiency for the electron-muon dilepton trigger paths used in the H→WW analysis. \n",
    "The trigger efficiency quantifies the fraction of events that pass physics selection criteria and successfully fire the required High-Level Trigger (HLT) paths.\n",
    "\n",
    "## Physics Context\n",
    "In high-energy physics experiments, triggers are essential hardware/software filters that select interesting collision events from the billions of interactions per second. \n",
    "For the H→WW→e-μ analysis, we rely on specific HLT paths that require either:\n",
    "- A muon with pT > 12 GeV and an electron with pT > 23 GeV, OR\n",
    "- An electron with pT > 23 GeV and a muon with pT > 12 GeV\n",
    "\n",
    "The trigger efficiency describes how reliably these paths select events that meet our physics criteria.\n",
    "\n",
    "## Purpose\n",
    "Understanding trigger efficiency is critical because:\n",
    "1. **Correction Factor**: We need to correct Monte Carlo simulations to match real detector performance\n",
    "2. **Event Yield**: Determines how many events we retain for analysis\n",
    "3. **Systematic Uncertainty**: Differences between data and MC efficiency contribute to analysis uncertainty\n",
    "\n",
    "## Inputs\n",
    "- **Data Files**: 48 NanoAOD ROOT files from 2016 Run periods G and H (MuonEG dataset)\n",
    "- **Golden JSON**: Certification file that marks good data-taking periods as valid\n",
    "- **Event Selection**: Collision events containing exactly 2 leptons (e-μ pairs) passing quality criteria\n",
    "\n",
    "## Outputs\n",
    "- **Trigger Efficiency**: A single scalar value (~91.29%) representing the fraction of selected events that pass HLT\n",
    "- **Detailed Breakdown**: File and sample-level statistics for validation\n",
    "\n",
    "## Analysis Workflow\n",
    "1. **Load Data**: Read NanoAOD files with distributed processing (Dask)\n",
    "2. **Apply Data Quality**: Filter events using golden JSON certification\n",
    "3. **Lepton Selection**: Identify tight electrons and muons passing isolation criteria\n",
    "4. **Event Selection**: Apply kinematic cuts to build a pure dilepton sample\n",
    "5. **Trigger Matching**: Count how many events fire the required HLT paths\n",
    "6. **Efficiency Calculation**: Compute the ratio of triggered events to selected events\n",
    "\n",
    "<!-- **Efficiency Formula**:  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7c9926-0d0c-473f-bfb4-7f047c4aebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc \n",
    "import psutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "print(\"All imports added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274a1508-d354-43c3-ace0-ec467e70b3fd",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "### Required Libraries\n",
    "- **uproot**: Reading ROOT files from CERN's storage\n",
    "- **awkward**: Efficient array operations on nested data structures\n",
    "- **numpy**: Numerical computations\n",
    "- **dask**: Distributed parallel processing across multiple workers\n",
    "- **vector**: 4-vector physics calculations (energy-momentum)\n",
    "\n",
    "### Distributed Processing\n",
    "This notebook uses Dask to process 48 files in parallel, drastically reducing runtime. \n",
    "A Client connection distributes tasks across available worker nodes, each processing independent data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2676427-fdb7-4d7a-af14-d8e25a5aca48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-edab41de-0504-11f1-80ed-428df2165000</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/anujraghav.physics@gmail.com/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-0883690a-89f6-4d6e-bc49-2476b0168e90</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://192.168.202.5:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/8787/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 2.89 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: htcondor--25087124.0--</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://129.93.182.107:44115\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/user/anujraghav.physics@gmail.com/proxy/33599/status\" target=\"_blank\">/user/anujraghav.physics@gmail.com/proxy/33599/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 2.89 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://172.19.0.3:37857\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /var/lib/condor/execute/dir_3267622/dask-scratch-space/worker-uzhh8npa\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 2.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 171.64 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 462.8115232872504 B\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 1.62 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.202.5:8786' processes=1 threads=1, memory=2.89 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c94c8ca-bf1e-430a-8255-a3ad8a0201fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR:         /home/cms-jovyan\n",
      "PROJECT_DIR:     /home/cms-jovyan/H-to-WW-NanoAOD-analysis\n",
      "DATA_DIR:        /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/DATA\n",
      "AUX_DIR:         /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files\n",
      "GOLDEN_JSON:      /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\n",
      "JSON exists:     True\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = Path(os.environ.get(\"HOME\", \"/home/cms-jovyan\"))\n",
    "PROJECT_NAME = \"H-to-WW-NanoAOD-analysis\"\n",
    "\n",
    "PROJECT_DIR = HOME_DIR / PROJECT_NAME\n",
    "DATASETS_DIR = PROJECT_DIR / \"Datasets\"\n",
    "DATA_DIR = DATASETS_DIR / \"DATA\"\n",
    "AUX_DIR = PROJECT_DIR / \"Auxillary_files\"\n",
    "\n",
    "GOLDEN_JSON_PATH = AUX_DIR / \"Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\"\n",
    "\n",
    "RUN_PERIODS_2016 = {\n",
    "    \"Run2016G\": {\"run_min\": 278820, \"run_max\": 280385},\n",
    "    \"Run2016H\": {\"run_min\": 280919, \"run_max\": 284044}\n",
    "}\n",
    "\n",
    "print(f\"HOME_DIR:         {HOME_DIR}\")\n",
    "print(f\"PROJECT_DIR:     {PROJECT_DIR}\")\n",
    "print(f\"DATA_DIR:        {DATA_DIR}\")\n",
    "print(f\"AUX_DIR:         {AUX_DIR}\")\n",
    "print(f\"GOLDEN_JSON:      {GOLDEN_JSON_PATH}\")\n",
    "print(f\"JSON exists:     {GOLDEN_JSON_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1862d77-f119-467c-9544-9a0133fb0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FILES TO PROCESS\n",
      "======================================================================\n",
      "Data                :   48 files\n",
      "______________________________________________________________________\n",
      "TOTAL               :   48 files\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_MAPPING = {\n",
    "    'data' : \"Data\",\n",
    "}\n",
    "\n",
    "def load_urls_from_files(filepath, max_files = None):\n",
    "    urls = []\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        return urls\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('root://'):\n",
    "                urls.append(line)\n",
    "                if max_files and len(urls) >= max_files:\n",
    "                    break\n",
    "    return urls\n",
    "\n",
    "def load_all_files(data_dir, max_per_sample = None):\n",
    "\n",
    "    files_dict = {}\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Directory not found: {data_dir}\")\n",
    "        return files_dict\n",
    "\n",
    "    # Loop directly over files in the single data_dir\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        filename_lower = filename.lower().replace('.txt', '')\n",
    "\n",
    "        label = None\n",
    "\n",
    "        for pattern, sample_label in SAMPLE_MAPPING.items():\n",
    "            if pattern in filename_lower:\n",
    "                label = sample_label\n",
    "                break\n",
    "\n",
    "        if not label:\n",
    "            print(f\" unknown file: {filename}- skipping\")\n",
    "            continue\n",
    "\n",
    "        urls = load_urls_from_files(filepath, max_per_sample)\n",
    "\n",
    "        if urls: \n",
    "            if label in files_dict:\n",
    "                files_dict[label].extend(urls)\n",
    "            else:\n",
    "                files_dict[label] = urls\n",
    "\n",
    "    return files_dict\n",
    "\n",
    "# files = load_all_files(DATA_DIR, max_per_sample=1)\n",
    "files = load_all_files(DATA_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES TO PROCESS\")\n",
    "print(\"=\"*70)\n",
    "total = 0\n",
    "for label, urls in files.items():\n",
    "    print(f\"{label:20s}: {len(urls):4d} files\")\n",
    "    total += len(urls)\n",
    "print(\"_\"*70)\n",
    "print(f\"{'TOTAL':20s}: {total:4d} files\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e416d-5a5d-4b08-a544-411330fd8fb7",
   "metadata": {},
   "source": [
    "## Step 1: Data Quality and Certification\n",
    "\n",
    "### Golden JSON Validation\n",
    "Not all recorded data is suitable for physics analysis. Detector issues, beam problems, or detector outages \n",
    "can occur during data-taking. The \"golden JSON\" file contains certified luminosity blocks (sub-run periods) \n",
    "where all detector subsystems were operational and data quality was verified.\n",
    "\n",
    "**What we do**: Filter events to only use data from certified runs and luminosity blocks\n",
    "**Why**: Ensures we only analyze good-quality data with reliable detector performance\n",
    "**How**: For each event, check if its run number and luminosity block appear in the golden JSON list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88a35496-8308-4785-b95a-0522e5145395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_golden_json(json_input, run_periods=None):\n",
    "    \"\"\"\n",
    "    Load golden JSON from either a file path (str) or a dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(json_input, str):\n",
    "        with open(json_input, 'r') as f:\n",
    "            golden_json = json.load(f)\n",
    "    elif isinstance(json_input, dict):\n",
    "        golden_json = json_input\n",
    "    else:\n",
    "        raise TypeError(f\"Expected str or dict, got {type(json_input)}\")\n",
    "    \n",
    "    valid_lumis = {}\n",
    "    for run_str, lumi_ranges in golden_json.items():\n",
    "        run = int(run_str)\n",
    "        \n",
    "        # Filter by run periods \n",
    "        if run_periods is not None: \n",
    "            in_period = any(\n",
    "                period['run_min'] <= run <= period['run_max']\n",
    "                for period in run_periods.values()\n",
    "            )\n",
    "            if not in_period:\n",
    "                continue\n",
    "        \n",
    "        valid_lumis[run] = [tuple(lr) for lr in lumi_ranges]\n",
    "    \n",
    "    return valid_lumis\n",
    "\n",
    "\n",
    "def apply_json_mask(arrays, json_input, run_periods=None):\n",
    "\n",
    "    valid_lumis = load_golden_json(json_input, run_periods)\n",
    "    \n",
    "    runs = ak.to_numpy(arrays.run)\n",
    "    lumis = ak.to_numpy(arrays.luminosityBlock)\n",
    "    \n",
    "    mask = np. zeros(len(runs), dtype=bool)\n",
    "    \n",
    "    for run, lumi_ranges in valid_lumis.items():\n",
    "        run_mask = (runs == run)\n",
    "        \n",
    "        if not np.any(run_mask):\n",
    "            continue\n",
    "        \n",
    "        # Check lumi sections \n",
    "        run_lumis = lumis[run_mask]\n",
    "        run_lumi_mask = np.zeros(len(run_lumis), dtype=bool)\n",
    "        \n",
    "        for lumi_start, lumi_end in lumi_ranges: \n",
    "            run_lumi_mask |= (run_lumis >= lumi_start) & (run_lumis <= lumi_end)\n",
    "        \n",
    "        mask[run_mask] = run_lumi_mask\n",
    "    \n",
    "    return ak.Array(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209a915-84d8-4975-bc55-7809f3fb0af6",
   "metadata": {},
   "source": [
    "## Step 2: Event Loading and Reconstruction\n",
    "\n",
    "### Reading NanoAOD Files\n",
    "NanoAOD (Nano Analysis Object Data) is a compressed ROOT format containing the essential physics objects \n",
    "for analysis: electrons, muons, jets, and missing energy.\n",
    "\n",
    "**What we read**:\n",
    "- **Leptons**: Electron and muon 4-momenta (pT, η, φ, mass) and quality flags\n",
    "- **Isolation**: Relative isolation variables (how much nearby activity surrounds the lepton)\n",
    "- **Triggers**: Boolean flags indicating which HLT paths fired\n",
    "- **Missing Energy**: PuppiMET (Particle Flow Missing Energy)\n",
    "- **Metadata**: Run and luminosity block numbers for data quality\n",
    "\n",
    "**Why batching**: Processing files in chunks (~1.25M events) manages memory efficiently while maintaining performance\n",
    "**How**: uproot iterates through ROOT trees in configurable batch sizes, with automatic retry logic for network timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "040e5d93-62f3-4c14-b631-fd85522b8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 1_250_000\n",
    "\n",
    "def load_events(file_url, batch_size=1_250_000, timeout=600, max_retries=3, retry_wait=10, is_data=False):\n",
    "    columns = [\n",
    "        \"Electron_pt\", \"Electron_eta\", \"Electron_phi\", \"Electron_mass\", \n",
    "        \"Electron_mvaFall17V2Iso_WP90\", \"Electron_charge\",\n",
    "        \n",
    "        \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_mass\", \n",
    "        \"Muon_tightId\", \"Muon_charge\", \"Muon_pfRelIso04_all\",\n",
    "        \"PuppiMET_pt\", \"PuppiMET_phi\",\n",
    "        \n",
    "        \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_mass\",\n",
    "        \"Jet_btagDeepFlavB\", \"nJet\", \"Jet_jetId\", \"Jet_puId\",\n",
    "\n",
    "        \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\",\n",
    "        \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"\n",
    "    ]\n",
    "\n",
    "    columns.extend([\"run\", \"luminosityBlock\"])\n",
    "        \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with uproot.open(file_url, timeout=timeout) as f:\n",
    "                tree = f['Events']\n",
    "                \n",
    "                for arrays in tree.iterate(columns, step_size=batch_size, library=\"ak\"):\n",
    "                    yield arrays\n",
    "                \n",
    "                return\n",
    "                \n",
    "        except (TimeoutError, OSError, IOError, ConnectionError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"      {error_type} on {file_name}\")\n",
    "                print(f\"       Retry {attempt+1}/{max_retries-1} in {retry_wait}s...\")\n",
    "                time.sleep(retry_wait)\n",
    "            else:\n",
    "                print(f\"     FAILED after {max_retries} attempts: {file_name}\")\n",
    "                print(f\"       Error: {str(e)[:100]}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            print(f\"     Unexpected error on {file_name}: {str(e)[:100]}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a27bb0-d59f-4e8c-8b4f-fdcabe26d752",
   "metadata": {},
   "source": [
    "## Step 3: Lepton Selection (Object Identification)\n",
    "\n",
    "### Tight Lepton Criteria\n",
    "We select \"tight\" leptons that pass stringent quality criteria, ensuring they are real particles from collisions \n",
    "and not detector noise or misidentified background.\n",
    "\n",
    "**Tight Electrons**:\n",
    "- MVA ID (Multivariate Analysis): A machine learning score indicating electron-like properties\n",
    "- We use the \"Fall17V2Iso_WP90\" working point, which requires MVA score > 0.9\n",
    "\n",
    "**Tight Muons**:\n",
    "- Tight ID flag: A set of quality cuts on track fit and chamber hits\n",
    "- Isolation requirement: Relative isolation < 0.15 (pfRelIso04_all)\n",
    "  - This ensures little hadronic/electromagnetic activity near the muon direction\n",
    "  - Prevents selection of jets or tau leptons misidentified as muons\n",
    "\n",
    "**What we do**: Create a combined lepton collection containing both tight electrons and tight muons\n",
    "**Why**: Tight selection reduces background contamination and ensures we study real leptons\n",
    "**How**: Apply boolean masks to filter lepton arrays, then concatenate electron and muon collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e802140-cd61-4d62-91db-e2af5834d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tight_leptons(arrays):\n",
    "    tight_electron_mask = arrays.Electron_mvaFall17V2Iso_WP90 == 1\n",
    "    tight_muon_mask = (arrays.Muon_tightId == 1) & (arrays.Muon_pfRelIso04_all < 0.15)\n",
    "    \n",
    "    tight_electrons = ak.zip({\n",
    "        \"pt\": arrays.Electron_pt[tight_electron_mask],\n",
    "        \"eta\": arrays.Electron_eta[tight_electron_mask],\n",
    "        \"phi\": arrays.Electron_phi[tight_electron_mask],\n",
    "        \"mass\": arrays.Electron_mass[tight_electron_mask],\n",
    "        \"charge\": arrays.Electron_charge[tight_electron_mask],\n",
    "        \"flavor\": ak.values_astype(ak.ones_like(arrays.Electron_pt[tight_electron_mask]) * 11, \"int32\")\n",
    "    })\n",
    "    \n",
    "    tight_muons = ak.zip({\n",
    "        \"pt\": arrays.Muon_pt[tight_muon_mask],\n",
    "        \"eta\": arrays.Muon_eta[tight_muon_mask],\n",
    "        \"phi\": arrays.Muon_phi[tight_muon_mask],\n",
    "        \"mass\": arrays.Muon_mass[tight_muon_mask],\n",
    "        \"charge\": arrays.Muon_charge[tight_muon_mask],\n",
    "        \"flavor\": ak.values_astype(ak.ones_like(arrays.Muon_pt[tight_muon_mask]) * 13, \"int32\")\n",
    "    })\n",
    "    \n",
    "    tight_leptons = ak.concatenate([tight_electrons, tight_muons], axis=1)\n",
    "    return tight_leptons\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09e299-9f2a-49ea-ab56-36f910d55226",
   "metadata": {},
   "source": [
    "## Step 4: Kinematic Variable Calculation\n",
    "\n",
    "### Physics Variables for Event Selection\n",
    "To ensure we're selecting genuine H→WW→e-μ events, we calculate several kinematic variables from the lepton and MET 4-momenta.\n",
    "\n",
    "**Key Variables**:\n",
    "- **M_ll (Dilepton Mass)**: Invariant mass of the two leptons\n",
    "  - H→WW events show a characteristic mass distribution\n",
    "  - We cut at M_ll > 12 GeV to reject low-mass backgrounds (e.g., from jets)\n",
    "\n",
    "- **pT_ll (Dilepton Momentum)**: Combined transverse momentum of both leptons\n",
    "  - Higgs particles produced at high pT indicate interesting events\n",
    "  - Cut at pT_ll > 30 GeV\n",
    "\n",
    "- **MT_Higgs (Higgs Transverse Mass)**: Constructed from both leptons and missing energy\n",
    "  - Accounts for the undetected neutrinos from W decays\n",
    "  - Cut at MT_Higgs > 60 GeV to suppress background\n",
    "\n",
    "- **MT_L2 (Subleading Lepton Transverse Mass)**: Between the lower-pT lepton and MET\n",
    "  - Sensitive to W decay kinematics\n",
    "  - Cut at MT_L2 > 30 GeV\n",
    "\n",
    "- **ΔΦ (Azimuthal angle difference)**: Angle between the two leptons in the transverse plane\n",
    "  - Wrapped to the range [-π, π]\n",
    "\n",
    "**Why these cuts**: Each variable helps distinguish H→WW signal from background processes\n",
    "**How**: Construct 4-vectors from lepton properties, use vector addition/subtraction for combined quantities, apply trigonometry for angular calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8b01225-4cc0-4c68-ba29-1a961ea5bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_angle_to_pi(angle):\n",
    "    \n",
    "    return (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "def create_lepton_vector(lepton):\n",
    "    \"\"\"Create 4-vector from lepton properties \"\"\"\n",
    "    return vector.array({\n",
    "        \"pt\": lepton.pt,\n",
    "        \"eta\": lepton.eta,\n",
    "        \"phi\": lepton.phi,\n",
    "        \"mass\": lepton.mass\n",
    "    })\n",
    "\n",
    "def cal_kinematic_var(leading, subleading, met):\n",
    "\n",
    "    # Create vectors\n",
    "    lepton_1 = create_lepton_vector(leading)\n",
    "    lepton_2 = create_lepton_vector(subleading)\n",
    "\n",
    "\n",
    "    dilepton = lepton_1 + lepton_2\n",
    "    \n",
    "    #  Basic Variables\n",
    "    mll = dilepton.mass\n",
    "    ptll = dilepton.pt\n",
    "    dphi = wrap_angle_to_pi(leading.phi - subleading.phi)\n",
    "\n",
    "    # Higgs Transverse Mass \n",
    "    dll_et = np.sqrt(dilepton.pt**2 + dilepton.mass**2)\n",
    "    mt_higgs_dphi = wrap_angle_to_pi(dilepton.phi - met.phi)\n",
    "    term_1 = mll**2\n",
    "    term_2 = 2 * (dll_et * met.pt - dilepton.pt * met.pt * np.cos(mt_higgs_dphi))\n",
    "    \n",
    "    mt_higgs = np.sqrt(term_1 + term_2)\n",
    "    \n",
    "\n",
    "    # Lepton 2 Transverse Mass\n",
    "    mt_l2_met_dphi = wrap_angle_to_pi(subleading.phi - met.phi)\n",
    "    mt_l2_met = np.sqrt(2 * subleading.pt * met.pt * (1 - np.cos(mt_l2_met_dphi)))\n",
    "\n",
    "\n",
    "    return mll, ptll, dphi, mt_higgs, mt_l2_met\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1e76c-9ad4-43e0-9f43-286c4d502286",
   "metadata": {},
   "source": [
    "## Step 5: Event Selection (Kinematic Cuts & Trigger)\n",
    "\n",
    "### Electron-Muon Pair Selection\n",
    "We select events containing exactly one electron and one muon (dilepton events) passing multiple criteria.\n",
    "\n",
    "**Selection Criteria Applied**:\n",
    "\n",
    "1. **Multiplicity**: Exactly 2 tight leptons (e-μ pair)\n",
    "\n",
    "2. **Flavor Requirement**: One electron (PDG ID = 11) and one muon (PDG ID = 13)\n",
    "   - Rejects e-e or μ-μ pairs which come from different processes\n",
    "\n",
    "3. **Charge Requirement**: Opposite sign (charge product < 0)\n",
    "   - Rejects same-sign pairs which are rare in signal but common in backgrounds\n",
    "\n",
    "4. **Transverse Momentum (pT)**:\n",
    "   - Leading lepton: pT > 25 GeV\n",
    "   - Subleading lepton: pT > 15 GeV\n",
    "   - Ensures trigger efficiency and online reconstruction capability\n",
    "\n",
    "5. **Pseudorapidity (η)**:\n",
    "   - Electrons: |η| < 2.5 (detector coverage)\n",
    "   - Muons: |η| < 2.4 (detector coverage)\n",
    "   - Ensures leptons are in well-instrumented detector regions\n",
    "\n",
    "6. **Kinematic Variables** (from Step 4):\n",
    "   - M_ll > 12 GeV, pT_ll > 30 GeV\n",
    "   - MT_Higgs > 60 GeV, MT_L2 > 30 GeV\n",
    "   - MET > 20 GeV (indicating W decays with neutrinos)\n",
    "\n",
    "7. **Trigger Requirement** (for efficiency calculation):\n",
    "   - Event must fire one of two HLT paths:\n",
    "     - `HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ`: Muon pT > 12 & Electron pT > 23\n",
    "     - `HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ`: Electron pT > 23 & Muon pT > 12\n",
    "   - \"DZ\" in the trigger name means the leptons must be matched (Δz < threshold)\n",
    "\n",
    "**Efficiency Definition**:\n",
    "- **Denominator**: Events passing all kinematic cuts (but not necessarily HLT)\n",
    "- **Numerator**: Events passing kinematics AND HLT\n",
    "- **Result**: Ratio tells us what fraction of signal-like events are retained by the trigger\n",
    "\n",
    "**What we do**: Count events in two categories: (1) kinematics only, (2) kinematics + HLT\n",
    "**Why**: Enables direct calculation of trigger efficiency as a ratio\n",
    "**How**: Apply boolean masks sequentially, count surviving events at each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4dfdb74-9707-414b-8ccf-af60640db158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_emu_events(tight_leptons, arrays, met):\n",
    "    # Sort leptons\n",
    "    sorted_leptons = tight_leptons[ak.argsort(tight_leptons.pt, ascending=False)]\n",
    "\n",
    "    mask_2lep = ak.num(sorted_leptons) == 2\n",
    "    \n",
    "    events_2lep = sorted_leptons[mask_2lep]\n",
    "    arrays_2lep = arrays[mask_2lep]  # Keeps HLT branches aligned\n",
    "    met_2lep = met[mask_2lep]\n",
    "\n",
    "    if len(events_2lep) == 0:\n",
    "        return 0, 0, None\n",
    "\n",
    "    # Kinematic Cuts \n",
    "    leading = events_2lep[:, 0]\n",
    "    subleading = events_2lep[:, 1]\n",
    "\n",
    "        \n",
    "    # calculating variables \n",
    "    mll, ptll, dphi, mt_higgs, mt_l2_met = cal_kinematic_var(leading, subleading, met_2lep)\n",
    "\n",
    "    # CUTS\n",
    "    mask_flavor = ((leading.flavor == 13) & (subleading.flavor == 11)) | \\\n",
    "                  ((leading.flavor == 11) & (subleading.flavor == 13))\n",
    "    mask_charge = leading.charge * subleading.charge < 0\n",
    "    mask_pt = (leading.pt > 25) & (subleading.pt > 15)\n",
    "\n",
    "    pass_eta_leading = ((leading.flavor == 11) & (abs(leading.eta) < 2.5)) | \\\n",
    "                       ((leading.flavor == 13) & (abs(leading.eta) < 2.4))\n",
    "                       \n",
    "    pass_eta_subleading = ((subleading.flavor == 11) & (abs(subleading.eta) < 2.5)) | \\\n",
    "                          ((subleading.flavor == 13) & (abs(subleading.eta) < 2.4))\n",
    "    \n",
    "    mask_eta = pass_eta_leading & pass_eta_subleading\n",
    "    other_masks = ((mll > 12) &\n",
    "                  (mt_higgs > 60) &\n",
    "                  (mt_l2_met > 30) &\n",
    "                  (ptll > 30) &\n",
    "                  (met_2lep.pt > 20))\n",
    "    # mask_eta < 2.4\n",
    "    # mll >20\n",
    "    # mll from top 12 = , ptll cut same as Sr> 30, met > 20\n",
    "\n",
    "    # kinematics_mask =  mask_flavor & mask_charge & mask_pt & mask_eta & other_masks\n",
    "\n",
    "    # E-Mu Selected mask\n",
    "    mask_emu_kinematics = mask_flavor & mask_charge & mask_pt & mask_eta & other_masks\n",
    "\n",
    "    # Trigger (HLT) Cut\n",
    "    mask_hlt = (arrays_2lep.HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ == 1) | \\\n",
    "               (arrays_2lep.HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ == 1)\n",
    "\n",
    "    #  Final Masks\n",
    "    # Events passing ONLY kinematics\n",
    "    events_passing_emu = events_2lep[mask_emu_kinematics]\n",
    "    \n",
    "    # Events passing Kinematics AND HLT\n",
    "    final_mask = mask_emu_kinematics & mask_hlt\n",
    "    events_passing_all = events_2lep[final_mask]\n",
    "\n",
    "    # Return counts and the final objects\n",
    "    n_emu = len(events_passing_emu)\n",
    "    n_final = len(events_passing_all)\n",
    "    \n",
    "    return n_emu, n_final, events_passing_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8421e1-6713-42b9-9dc3-16596543cb97",
   "metadata": {},
   "source": [
    "## Step 6: Distributed Processing Framework\n",
    "\n",
    "### Parallel File Processing\n",
    "With 48 data files, we use Dask to process them in parallel across multiple worker nodes. \n",
    "This dramatically reduces runtime (184 seconds total vs potentially hours sequentially).\n",
    "\n",
    "**Processing Strategy**:\n",
    "1. Create a \"processor function\" with the golden JSON and run periods baked in (closure pattern)\n",
    "2. Submit all 48 files as independent tasks to Dask workers\n",
    "3. Each worker:\n",
    "   - Loads events from one file in batches\n",
    "   - Applies JSON validation\n",
    "   - Performs lepton and event selection\n",
    "   - Counts kinematic and HLT events\n",
    "4. Collect results from all workers and aggregate statistics\n",
    "\n",
    "**Error Handling**:\n",
    "- Network timeouts on ROOT file access: Automatic retry (up to 3 attempts)\n",
    "- Processing errors: Caught and logged, file marked as failed\n",
    "- Allows analysis to complete even if a few files become unavailable\n",
    "\n",
    "**What happens**: Each file is processed independently and in parallel.\n",
    "**Why**: Reduces wall-clock time from hours to minutes.\n",
    "**How**: Dask Client maps the processor function across all file URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "350fabf9-8e8a-481a-bfdc-2d1479cb34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "def make_processor(golden_json_data, run_periods):\n",
    "    \"\"\"\n",
    "    Factory function that returns a worker function with \n",
    "    JSON data and Run Periods baked in (Closure Pattern).\n",
    "    \"\"\"\n",
    "\n",
    "    def processing_file(label, file_url, file_idx):\n",
    "        \n",
    "        # Initialize Counters\n",
    "        count_emu_kinematics = 0\n",
    "        count_emu_hlt = 0\n",
    "        \n",
    "        file_name = file_url.split('/')[-1] \n",
    "        is_data = True\n",
    "        \n",
    "        max_file_retries = 3\n",
    "\n",
    "        for file_attempt in range(max_file_retries):\n",
    "            try:\n",
    "                # Load Events\n",
    "                for arrays in load_events(file_url, batch_size=1_250_000, is_data=is_data):\n",
    "                    \n",
    "                    #  Apply JSON Mask to Data\n",
    "                    if is_data and golden_json_data is not None:\n",
    "                        try:\n",
    "                            json_mask = apply_json_mask(arrays, golden_json_data, run_periods=run_periods)\n",
    "                            if np.sum(json_mask) == 0: continue\n",
    "                            arrays = arrays[json_mask]\n",
    "                        except Exception as e: \n",
    "                            print(f\"Warning: JSON mask failed for {file_name}: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Object Selection\n",
    "                    tight_leptons = select_tight_leptons(arrays)\n",
    "\n",
    "                    met = ak.zip({\"pt\": arrays.PuppiMET_pt, \"phi\": arrays.PuppiMET_phi})\n",
    "                    \n",
    "                    # Event Selection (Kinematics + HLT)\n",
    "                    n_emu, n_hlt, _ = select_emu_events(tight_leptons, arrays, met)\n",
    "                    \n",
    "                    #  Accumulate\n",
    "                    count_emu_kinematics += n_emu\n",
    "                    count_emu_hlt += n_hlt\n",
    "                \n",
    "                # Success\n",
    "                return label, count_emu_kinematics, count_emu_hlt, None\n",
    "\n",
    "            except (OSError, IOError, ValueError) as e:\n",
    "                if file_attempt < max_file_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                else: \n",
    "                    return label, 0, 0, f\"{file_name}: Failed after retries - {str(e)[:100]}\"\n",
    "            \n",
    "            except Exception as e:\n",
    "                return label, 0, 0, f\"{file_name}: Unexpected error - {str(e)[:100]}\"\n",
    "\n",
    "        return label, 0, 0, \"Unknown loop exit\"\n",
    "\n",
    "    # Return the inner function\n",
    "    return processing_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc480d-01f1-4aaf-b0f7-4f58ffa2042d",
   "metadata": {},
   "source": [
    "## Step 7: Main Analysis - Computing Trigger Efficiency\n",
    "\n",
    "### Execution Summary\n",
    "The code below:\n",
    "1. **Loads the golden JSON** into memory (contains ~20k valid luminosity blocks)\n",
    "2. **Creates file lists** from text files in the data directory\n",
    "3. **Submits 48 files** to the Dask cluster for parallel processing\n",
    "4. **Monitors progress** (bar shows completion percentage)\n",
    "5. **Aggregates results** from all workers\n",
    "6. **Calculates efficiency** as: (HLT events) / (Kinematic events) × 100%\n",
    "7. **Reports statistics** with error handling\n",
    "\n",
    "### Expected Output\n",
    "The table shows:\n",
    "- **SAMPLE**: Data or MC (here, only Data)\n",
    "- **FILES**: Number of files processed for this sample\n",
    "- **KINEMATICS**: Events passing physics selection criteria\n",
    "- **HLT PASS**: Events that also fired the required trigger\n",
    "- **TRIG EFF**: Percentage of selected events that pass the trigger\n",
    "\n",
    "For this 2016 data sample: **~91.3% of selected e-μ events fire the HLT paths**\n",
    "\n",
    "This efficiency will be used as a correction factor applied to simulated events.\n",
    "\n",
    "### Performance\n",
    "- **Total Time**: 184.6 seconds to process 48 files\n",
    "- **Throughput**: 3.85 seconds per file (includes I/O, network, processing)\n",
    "- **Scaling**: Roughly linear with number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d0b61ba-9ea2-40be-a39c-11479aec048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRIGGER EFFICIENCY PROCESSING START\n",
      "======================================================================\n",
      "Preparing file lists...\n",
      "  Data: Validation enabled (48 files)\n",
      "\n",
      "Submitting 48 files to the cluster...\n",
      "\n",
      "======================================================================\n",
      "SAMPLE               | FILES    |     KINEMATICS |     HLT PASS |   TRIG EFF\n",
      "======================================================================\n",
      "Data                 | 48       |        132,784 |      121,224 |     91.29%\n",
      "______________________________________________________________________\n",
      "TOTAL                | 48       |        132,784 |      121,224 |     91.29%\n",
      "======================================================================\n",
      "\n",
      "Done in 184.6s (3.85s/file)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# MAIN PROCESSING (Trigger Efficiency)\n",
    "\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from dask.distributed import progress\n",
    "\n",
    "print(f\"\\n{'='*70}\\nTRIGGER EFFICIENCY PROCESSING START\\n{'='*70}\")\n",
    "\n",
    "golden_json_data = None\n",
    "if GOLDEN_JSON_PATH.exists():\n",
    "    # print(f\"Reading Golden JSON: {GOLDEN_JSON_PATH.name}\")\n",
    "    with open(GOLDEN_JSON_PATH, 'r') as f:\n",
    "        golden_json_data = json.load(f)\n",
    "    # print(f\"  Loaded {len(golden_json_data)} runs into memory\\n\")\n",
    "else:\n",
    "    print(f\"WARNING: Golden JSON not found at {GOLDEN_JSON_PATH}\")\n",
    "\n",
    "processing_task = make_processor(\n",
    "    golden_json_data=golden_json_data,\n",
    "    run_periods=RUN_PERIODS_2016\n",
    ")\n",
    "\n",
    "arg_labels = []\n",
    "arg_urls = []\n",
    "arg_indices = []\n",
    "\n",
    "print(\"Preparing file lists...\")\n",
    "\n",
    "for label, urls in files.items():\n",
    "    is_data = (label == 'Data')\n",
    "    \n",
    "    if is_data:\n",
    "        if golden_json_data is not None:\n",
    "             print(f\"  {label}: Validation enabled ({len(urls)} files)\")\n",
    "    \n",
    "    for file_idx, file_url in enumerate(urls):\n",
    "        arg_labels.append(label)\n",
    "        arg_urls.append(str(file_url))\n",
    "        arg_indices.append(file_idx)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "print(f\"\\nSubmitting {len(arg_urls)} files to the cluster...\")\n",
    "\n",
    "futures = client.map(\n",
    "    processing_task,    \n",
    "    arg_labels,\n",
    "    arg_urls,\n",
    "    arg_indices,\n",
    "    retries=1\n",
    ")\n",
    "\n",
    "progress(futures)\n",
    "results = client.gather(futures)\n",
    "elapsed = time.perf_counter() - start_time\n",
    "\n",
    "final_stats = defaultdict(lambda: [0, 0, 0]) \n",
    "errors = []\n",
    "\n",
    "for label, n_kinematics, n_hlt, error in results:\n",
    "    if error:\n",
    "        errors.append((label, error))\n",
    "    else:\n",
    "        stats = final_stats[label]\n",
    "        stats[0] += n_kinematics # Denominator (Events passing cuts)\n",
    "        stats[1] += n_hlt        # Numerator (Events passing cuts + HLT)\n",
    "        stats[2] += 1            # File count\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'SAMPLE':<20} | {'FILES':<8} | {'KINEMATICS':>14} | {'HLT PASS':>12} | {'TRIG EFF':>10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tot_kinematics = tot_hlt = tot_files = 0\n",
    "\n",
    "for label, (n_kinematics, n_hlt, n_files) in sorted(final_stats.items()):\n",
    "    eff = (n_hlt / n_kinematics * 100) if n_kinematics > 0 else 0.0\n",
    "    \n",
    "    print(f\"{label:<20} | {n_files:<8} | {n_kinematics:>14,} | {n_hlt:>12,} | {eff:>9.2f}%\")\n",
    "    \n",
    "    tot_kinematics += n_kinematics\n",
    "    tot_hlt += n_hlt\n",
    "    tot_files += n_files\n",
    "\n",
    "print(\"_\"*70)\n",
    "tot_eff = (tot_hlt / tot_kinematics * 100) if tot_kinematics > 0 else 0.0\n",
    "print(f\"{'TOTAL':<20} | {tot_files:<8} | {tot_kinematics:>14,} | {tot_hlt:>12,} | {tot_eff:>9.2f}%\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if errors:\n",
    "    print(f\"\\n[!] Encountered {len(errors)} errors:\")\n",
    "    for label, err in errors[:5]: print(f\"  - {label}: {err}\")\n",
    "    if len(errors) > 5: print(f\"  ... and {len(errors)-5} more.\")\n",
    "\n",
    "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(arg_urls):.2f}s/file)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a70adbd-ab95-422c-954d-7fab3479dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Successful!\n",
      "Total Branches found: 1380\n",
      "============================================================\n",
      "HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\n",
      "HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\n"
     ]
    }
   ],
   "source": [
    "#get name of the branch required for trigger efficiency \n",
    "\n",
    "# DATA\n",
    "root_file_name = \"root://eospublic.cern.ch//eos/opendata/cms/Run2016G/MuonEG/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/120000/2ADBED61-A06A-D64B-BE90-E9B267D15700.root\"\n",
    "\n",
    "with uproot.open(root_file_name) as file:\n",
    "        # Access the Events tree\n",
    "        if \"Events\" not in file:\n",
    "            print(\"Error: 'Events' tree not found in file.\")\n",
    "        else:\n",
    "            tree = file[\"Events\"]\n",
    "            branches = tree.keys()\n",
    "            \n",
    "            print(f\"\\nConnection Successful!\")\n",
    "            print(f\"Total Branches found: {len(branches)}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Print all branches alphabetically\n",
    "            for branch in sorted(branches):\n",
    "                if \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\" in branch or \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"  in branch:\n",
    "                    print(branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c766e7b-342b-4c64-9be5-02b2e3fb6bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
