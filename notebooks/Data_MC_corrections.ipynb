{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ad64f7-ba57-4d4e-9ff3-f108b1589e06",
   "metadata": {},
   "source": [
    "## This notebook is for Data and MC corrections:\n",
    "1. Trigger Efficiencies\n",
    "2. Leptom effeciencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef4bad-a51d-429e-b234-b50da3f8796c",
   "metadata": {},
   "source": [
    "## TRIGGER EFFICIENCY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2b291-f93e-46c1-b8df-98f8956f888c",
   "metadata": {},
   "source": [
    "### Only for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe41238-7d38-45ca-9dc0-25a559250ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc \n",
    "import psutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "print(\"All imports added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ee6dfb-8bbd-4c84-bf52-7a51c11e245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR:         /home/cms-jovyan\n",
      "PROJECT_DIR:     /home/cms-jovyan/H-to-WW-NanoAOD-analysis\n",
      "DATA_DIR:        /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/DATA\n",
      "MC_DIR:          /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Datasets/MC_samples\n",
      "AUX_DIR:         /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files\n",
      "GOLDEN_JSON:      /home/cms-jovyan/H-to-WW-NanoAOD-analysis/Auxillary_files/Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\n",
      "JSON exists:     True\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = Path(os.environ.get(\"HOME\", \"/home/cms-jovyan\"))\n",
    "PROJECT_NAME = \"H-to-WW-NanoAOD-analysis\"\n",
    "\n",
    "PROJECT_DIR = HOME_DIR / PROJECT_NAME\n",
    "DATASETS_DIR = PROJECT_DIR / \"Datasets\"\n",
    "DATA_DIR = DATASETS_DIR / \"DATA\"\n",
    "MC_DIR = DATASETS_DIR / \"MC_samples\"\n",
    "AUX_DIR = PROJECT_DIR / \"Auxillary_files\"\n",
    "\n",
    "GOLDEN_JSON_PATH = AUX_DIR / \"Cert_271036-284044_13TeV_Legacy2016_Collisions16_JSON.txt\"\n",
    "\n",
    "RUN_PERIODS_2016 = {\n",
    "    \"Run2016G\": {\"run_min\": 278820, \"run_max\": 280385},\n",
    "    \"Run2016H\": {\"run_min\": 280919, \"run_max\": 284044}\n",
    "}\n",
    "\n",
    "print(f\"HOME_DIR:         {HOME_DIR}\")\n",
    "print(f\"PROJECT_DIR:     {PROJECT_DIR}\")\n",
    "print(f\"DATA_DIR:        {DATA_DIR}\")\n",
    "print(f\"MC_DIR:          {MC_DIR}\")\n",
    "print(f\"AUX_DIR:         {AUX_DIR}\")\n",
    "print(f\"GOLDEN_JSON:      {GOLDEN_JSON_PATH}\")\n",
    "print(f\"JSON exists:     {GOLDEN_JSON_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef0c6fb-d197-4752-8abe-62367b7612be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unknown file: VG.txt- skipping\n",
      " unknown file: Higgs.txt- skipping\n",
      " unknown file: WW.txt- skipping\n",
      " unknown file: Fakes.txt- skipping\n",
      " unknown file: VZ.txt- skipping\n",
      " unknown file: DYtoLL.txt- skipping\n",
      " unknown file: ggWW.txt- skipping\n",
      " unknown file: Top.txt- skipping\n",
      "\n",
      "======================================================================\n",
      "FILES TO PROCESS\n",
      "======================================================================\n",
      "Data                :    1 files\n",
      "______________________________________________________________________\n",
      "TOTAL               :    1 files\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_MAPPING = {\n",
    "    'data' : \"Data\",\n",
    "    # 'higgs' : \"ggH_HWW\",\n",
    "    # 'dytoll' : \"DY_to_Tau_Tau\",\n",
    "    # 'top' : \"Top_antitop\",\n",
    "    # 'fakes' : \"Fakes\",\n",
    "    # 'vz' : \"Diboson\",\n",
    "    # 'ggww' : \"ggWW\",\n",
    "    # 'ww' : 'WW',\n",
    "    # 'vg' : 'VG'\n",
    "}\n",
    "\n",
    "def load_urls_from_files(filepath, max_files = None):\n",
    "    urls = []\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        return urls\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and line.startswith('root://'):\n",
    "                urls.append(line)\n",
    "                if max_files and len(urls) >= max_files:\n",
    "                    break\n",
    "    return urls\n",
    "\n",
    "def load_all_files(data_dir, mc_dir, max_per_sample = None):\n",
    "\n",
    "    files_dict = {}\n",
    "\n",
    "    for directory in [data_dir, mc_dir]:\n",
    "        if not os.path.exists(directory):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            filename_lower = filename.lower().replace('.txt', '')\n",
    "\n",
    "            label = None\n",
    "\n",
    "            for pattern, sample_label in SAMPLE_MAPPING.items():\n",
    "                if pattern in filename_lower:\n",
    "                    label = sample_label\n",
    "                    break\n",
    "\n",
    "            if not label:\n",
    "                print(f\" unknown file: {filename}- skipping\")\n",
    "                continue\n",
    "\n",
    "            urls = load_urls_from_files(filepath, max_per_sample)\n",
    "\n",
    "            if urls: \n",
    "                if label in files_dict:\n",
    "                    files_dict[label].extend(urls)\n",
    "                else:\n",
    "                    files_dict[label] =urls\n",
    "\n",
    "    return files_dict\n",
    "\n",
    "files = load_all_files(DATA_DIR, MC_DIR, max_per_sample= 1)\n",
    "# files = load_all_files(DATA_DIR, MC_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES TO PROCESS\")\n",
    "print(\"=\"*70)\n",
    "total = 0\n",
    "for label, urls in files.items():\n",
    "    print(f\"{label:20s}: {len(urls):4d} files\")\n",
    "    total += len(urls)\n",
    "print(\"_\"*70)\n",
    "print(f\"{'TOTAL':20s}: {total:4d} files\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e33e641c-e346-4fe3-aa71-c7a9443b324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_golden_json(json_input, run_periods=None):\n",
    "    \"\"\"\n",
    "    Load golden JSON from either a file path (str) or a dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(json_input, str):\n",
    "        with open(json_input, 'r') as f:\n",
    "            golden_json = json.load(f)\n",
    "    elif isinstance(json_input, dict):\n",
    "        golden_json = json_input\n",
    "    else:\n",
    "        raise TypeError(f\"Expected str or dict, got {type(json_input)}\")\n",
    "    \n",
    "    valid_lumis = {}\n",
    "    for run_str, lumi_ranges in golden_json.items():\n",
    "        run = int(run_str)\n",
    "        \n",
    "        # Filter by run periods \n",
    "        if run_periods is not None: \n",
    "            in_period = any(\n",
    "                period['run_min'] <= run <= period['run_max']\n",
    "                for period in run_periods.values()\n",
    "            )\n",
    "            if not in_period:\n",
    "                continue\n",
    "        \n",
    "        valid_lumis[run] = [tuple(lr) for lr in lumi_ranges]\n",
    "    \n",
    "    return valid_lumis\n",
    "\n",
    "\n",
    "def apply_json_mask(arrays, json_input, run_periods=None):\n",
    "\n",
    "    valid_lumis = load_golden_json(json_input, run_periods)\n",
    "    \n",
    "    runs = ak.to_numpy(arrays.run)\n",
    "    lumis = ak.to_numpy(arrays.luminosityBlock)\n",
    "    \n",
    "    mask = np. zeros(len(runs), dtype=bool)\n",
    "    \n",
    "    for run, lumi_ranges in valid_lumis.items():\n",
    "        run_mask = (runs == run)\n",
    "        \n",
    "        if not np.any(run_mask):\n",
    "            continue\n",
    "        \n",
    "        # Check lumi sections \n",
    "        run_lumis = lumis[run_mask]\n",
    "        run_lumi_mask = np.zeros(len(run_lumis), dtype=bool)\n",
    "        \n",
    "        for lumi_start, lumi_end in lumi_ranges: \n",
    "            run_lumi_mask |= (run_lumis >= lumi_start) & (run_lumis <= lumi_end)\n",
    "        \n",
    "        mask[run_mask] = run_lumi_mask\n",
    "    \n",
    "    return ak.Array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48f4f36-672e-4679-8a22-1c5556a406ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Successful!\n",
      "Total Branches found: 1380\n",
      "============================================================\n",
      "HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\n",
      "HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\n"
     ]
    }
   ],
   "source": [
    "#get name of the branch required for trigger efficiency \n",
    "\n",
    "# DATA\n",
    "root_file_name = \"root://eospublic.cern.ch//eos/opendata/cms/Run2016G/MuonEG/NANOAOD/UL2016_MiniAODv2_NanoAODv9-v1/120000/2ADBED61-A06A-D64B-BE90-E9B267D15700.root\"\n",
    "\n",
    "#  MC \n",
    "\n",
    "# file_url = \"root://eospublic.cern.ch//eos/opendata/cms/mc/RunIISummer20UL16NanoAODv9/DYJetsToLL_M-50_TuneCP5_13TeV-madgraphMLM-pythia8/NANOAODSIM/106X_mcRun2_asymptotic_v17-v1/40000/14B6A8AE-C9FE-D744-80A4-DDE5D008C1CD.root\"\n",
    "\n",
    "with uproot.open(root_file_name) as file:\n",
    "        # Access the Events tree\n",
    "        if \"Events\" not in file:\n",
    "            print(\"Error: 'Events' tree not found in file.\")\n",
    "        else:\n",
    "            tree = file[\"Events\"]\n",
    "            branches = tree.keys()\n",
    "            \n",
    "            print(f\"\\nConnection Successful!\")\n",
    "            print(f\"Total Branches found: {len(branches)}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Print all branches alphabetically\n",
    "            for branch in sorted(branches):\n",
    "                if \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\" in branch or \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"  in branch:\n",
    "                    print(branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b5b221e-9c79-4dfe-8f9b-87b2568ec72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uproot\n",
    "\n",
    "Batch_size = 1_250_000\n",
    "\n",
    "def load_events(file_url, batch_size=1_250_000, timeout=600, max_retries=3, retry_wait=10, is_data=False):\n",
    "    columns = [\n",
    "        \"Electron_pt\", \"Electron_eta\", \"Electron_phi\", \"Electron_mass\", \n",
    "        \"Electron_mvaFall17V2Iso_WP90\", \"Electron_charge\",\n",
    "        \n",
    "        \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_mass\", \n",
    "        \"Muon_tightId\", \"Muon_charge\", \"Muon_pfRelIso04_all\",\n",
    "        \"PuppiMET_pt\", \"PuppiMET_phi\",\n",
    "        \n",
    "        \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_mass\",\n",
    "        \"Jet_btagDeepFlavB\", \"nJet\", \"Jet_jetId\", \"Jet_puId\",\n",
    "\n",
    "        \"HLT_Mu12_TrkIsoVVL_Ele23_CaloIdL_TrackIdL_IsoVL_DZ\",\n",
    "        \"HLT_Mu23_TrkIsoVVL_Ele12_CaloIdL_TrackIdL_IsoVL_DZ\"\n",
    "    ]\n",
    "\n",
    "    if is_data:\n",
    "        columns.extend([\"run\", \"luminosityBlock\"])\n",
    "    else:\n",
    "        columns.append(\"genWeight\")\n",
    "        \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with uproot.open(file_url, timeout=timeout) as f:\n",
    "                tree = f['Events']\n",
    "                \n",
    "                # Iterate through file chunks\n",
    "                for arrays in tree.iterate(columns, step_size=batch_size, library=\"ak\"):\n",
    "                    yield arrays\n",
    "                \n",
    "                # If iteration finishes successfully, exit the function\n",
    "                return\n",
    "                \n",
    "        except (TimeoutError, OSError, IOError, ConnectionError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"      {error_type} on {file_name}\")\n",
    "                print(f\"       Retry {attempt+1}/{max_retries-1} in {retry_wait}s...\")\n",
    "                time.sleep(retry_wait)\n",
    "            else:\n",
    "                print(f\"     FAILED after {max_retries} attempts: {file_name}\")\n",
    "                print(f\"       Error: {str(e)[:100]}\")\n",
    "                raise\n",
    "                \n",
    "        except Exception as e:\n",
    "            file_name = file_url.split('/')[-1]\n",
    "            print(f\"     Unexpected error on {file_name}: {str(e)[:100]}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2b65a-6c9a-40d2-99d7-b13ddbaae4f6",
   "metadata": {},
   "source": [
    "## TRIGGER PART\n",
    "\n",
    "Trigger efficiency = $\\frac{denominator + Trigger cut}{\\#\\ of\\ events\\ after\\ passing\\ preselection}$\n",
    "\n",
    "> Preselection inlcudes:\n",
    "> 1. 2 leptons\n",
    "> 2. lepton ID (Electron \\& Muon)\n",
    "> 3. |$\\eta$| < 2.5\n",
    "> 4. pT requirement: lead >25 and sublead > 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea86547f-892e-411a-b386-c49527e0d872",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3080967479.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    def select_e_mu_events(tight_leptons, met arrays):\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def preselection_passed_events():\n",
    "    \n",
    "    def select_tight_leptons(arrays, met_arrays):\n",
    "\n",
    "        tight_electron_mask = arrays.Electron_mvaFall17V2Iso_WP90 ==1\n",
    "        tight_muon_mask = (arrays.Muon_tightId == 1) & (arrays.Muon_pfRelIso4_all < 0.15)\n",
    "    \n",
    "        tight_electrons = ak.zip({\n",
    "            \"pt\": arrays.Electron_pt[tight_electron_mask],\n",
    "            \"eta\": arrays.Electron_eta[tight_electron_mask],\n",
    "            \"phi\": arrays.Electron_phi[tight_electron_mask],\n",
    "            \"mass\": arrays.Electron_mass[tight_electron_mask],\n",
    "            \"charge\": arrays.Electron_charge[tight_electron_mask],\n",
    "            \"flavor\": ak.ones_like(arrays.Electron_pt[tight_electron_mask]) * 11\n",
    "        })\n",
    "        \n",
    "        tight_muons = ak.zip({\n",
    "            \"pt\": arrays.Muon_pt[tight_muon_mask],\n",
    "            \"eta\": arrays.Muon_eta[tight_muon_mask],\n",
    "            \"phi\": arrays.Muon_phi[tight_muon_mask],\n",
    "            \"mass\": arrays.Muon_mass[tight_muon_mask],\n",
    "            \"charge\": arrays.Muon_charge[tight_muon_mask],\n",
    "            \"flavor\": ak.ones_like(arrays.Muon_pt[tight_muon_mask]) * 13\n",
    "        })\n",
    "    \n",
    "        tight_leptons = ak.concatenate([tight_electrons, tight_muons], axis = 1)\n",
    "\n",
    "    return tight_leptons, tight_electron_mask, tight_muon_mask\n",
    "\n",
    "\n",
    "    def select_e_mu_events(tight_leptons, met arrays):\n",
    "\n",
    "        sorted_leptons = tight_leptons[ak.argsort(tight_leptons.pt, ascending = False)]\n",
    "\n",
    "        mask_2lep = ak.num(sorted_leptons) == 2\n",
    "\n",
    "        events_2lep = sorted_leptons[mask_2lep]\n",
    "        met_2lep = met_arrays[mask_2lep]\n",
    "\n",
    "\n",
    "        if len(events_2lep) ==0:\n",
    "            return None, None, {}, None\n",
    "\n",
    "        leading = events_2lep[:,0]\n",
    "        subleading = events_2lep[:,1]\n",
    "\n",
    "        mask_1e1mu = ((leading.flavor == 13) & (subleading == 11)) | ((leading.flavor ==11) & (subleading.flavor == 13))\n",
    "\n",
    "        mask_opposite_charge = leading.charge*subleading.charge <0\n",
    "\n",
    "        mask_pt = (leading.pt>25) & (subleading.pt > 13)\n",
    "\n",
    "        mask_eta = (abs(leadin.eta)<2.5) & (abs(subleading.eta) < 2.5)\n",
    "\n",
    "        final_mask = mask_1e1mu & mask_opposite_charge & mask_pt & mask_eta\n",
    "\n",
    "    return final_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302e9b4-f269-49bc-bdc1-9712b80fc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLT_passed_events(arrays, met_arra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
